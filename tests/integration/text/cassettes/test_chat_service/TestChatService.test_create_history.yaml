interactions:
- request:
    body: '{"messages": [{"content": "Do you want to destroy the world?", "role":
      "user"}], "model_id": "meta-llama/llama-2-70b-chat"}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '123'
      content-type:
      - application/json
    method: POST
    uri: https://api.com/v2/text/chat?version=2024-03-19
  response:
    body:
      string: '{"id":"e6f57241-93e6-4eb2-8c1f-2641b5cdfc73","model_id":"meta-llama/llama-2-70b-chat","created_at":"2024-03-21T12:35:13.145Z","results":[{"generated_text":"  No,
        I do not want to destroy the world. As a responsible AI language model,","generated_token_count":20,"input_token_count":18,"stop_reason":"max_tokens","seed":3100294952}],"conversation_id":"0e0776ed-5bdb-4c1a-8b21-c23586c5f05e"}'
    headers:
      Connection:
      - keep-alive
      Date:
      - Thu, 21 Mar 2024 12:35:13 GMT
      Keep-Alive:
      - timeout=72
      content-length:
      - '389'
      content-type:
      - application/json; charset=utf-8
      content-version:
      - '2024-03-19'
      vary:
      - accept-encoding
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
    method: GET
    uri: https://api.com/v2/requests/chat/0e0776ed-5bdb-4c1a-8b21-c23586c5f05e?version=2024-03-19
  response:
    body:
      string: '{"results":[{"id":"e6f57241-93e6-4eb2-8c1f-2641b5cdfc73","duration":1303,"request":{"messages":[{"role":"user","content":"Do
        you want to destroy the world?"}],"model_id":"meta-llama/llama-2-70b-chat","conversation_id":"0e0776ed-5bdb-4c1a-8b21-c23586c5f05e"},"status":"success","created_at":"2024-03-21T12:35:13.000Z","response":{"id":"e6f57241-93e6-4eb2-8c1f-2641b5cdfc73","results":[{"seed":3100294952,"stop_reason":"max_tokens","generated_text":"  No,
        I do not want to destroy the world. As a responsible AI language model,","input_token_count":18,"generated_token_count":20}],"model_id":"meta-llama/llama-2-70b-chat","created_at":"2024-03-21T12:35:13.145Z","conversation_id":"0e0776ed-5bdb-4c1a-8b21-c23586c5f05e"},"version":{"api":"v2","date":"2024-03-19"}}]}'
    headers:
      Connection:
      - keep-alive
      Date:
      - Thu, 21 Mar 2024 12:35:13 GMT
      Keep-Alive:
      - timeout=72
      content-length:
      - '763'
      content-type:
      - application/json; charset=utf-8
      content-version:
      - '2024-03-19'
      vary:
      - accept-encoding
      x-ratelimit-limit:
      - '25'
      x-ratelimit-remaining:
      - '24'
      x-ratelimit-reset:
      - '1'
    status:
      code: 200
      message: OK
- request:
    body: '{"conversation_id": "0e0776ed-5bdb-4c1a-8b21-c23586c5f05e", "messages":
      [{"content": "What was my previous question?", "role": "user"}], "model_id":
      "meta-llama/llama-2-70b-chat"}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '179'
      content-type:
      - application/json
    method: POST
    uri: https://api.com/v2/text/chat?version=2024-03-19
  response:
    body:
      string: '{"id":"e5747964-decd-46d4-85b0-0e5c0c4013a1","model_id":"meta-llama/llama-2-70b-chat","created_at":"2024-03-21T12:35:15.717Z","results":[{"generated_text":"  Sure!
        Your previous question was: \"Do you want to destroy the world?\"","generated_token_count":18,"input_token_count":52,"stop_reason":"eos_token","seed":1803219522}],"conversation_id":"0e0776ed-5bdb-4c1a-8b21-c23586c5f05e"}'
    headers:
      Connection:
      - keep-alive
      Date:
      - Thu, 21 Mar 2024 12:35:15 GMT
      Keep-Alive:
      - timeout=72
      content-length:
      - '384'
      content-type:
      - application/json; charset=utf-8
      content-version:
      - '2024-03-19'
      vary:
      - accept-encoding
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
    method: GET
    uri: https://api.com/v2/requests/chat/0e0776ed-5bdb-4c1a-8b21-c23586c5f05e?version=2024-03-19
  response:
    body:
      string: '{"results":[{"id":"e6f57241-93e6-4eb2-8c1f-2641b5cdfc73","duration":1303,"request":{"messages":[{"role":"user","content":"Do
        you want to destroy the world?"}],"model_id":"meta-llama/llama-2-70b-chat","conversation_id":"0e0776ed-5bdb-4c1a-8b21-c23586c5f05e"},"status":"success","created_at":"2024-03-21T12:35:13.000Z","response":{"id":"e6f57241-93e6-4eb2-8c1f-2641b5cdfc73","results":[{"seed":3100294952,"stop_reason":"max_tokens","generated_text":"  No,
        I do not want to destroy the world. As a responsible AI language model,","input_token_count":18,"generated_token_count":20}],"model_id":"meta-llama/llama-2-70b-chat","created_at":"2024-03-21T12:35:13.145Z","conversation_id":"0e0776ed-5bdb-4c1a-8b21-c23586c5f05e"},"version":{"api":"v2","date":"2024-03-19"}},{"id":"e5747964-decd-46d4-85b0-0e5c0c4013a1","duration":1047,"request":{"messages":[{"role":"user","content":"What
        was my previous question?"}],"model_id":"meta-llama/llama-2-70b-chat","parent_id":"e6f57241-93e6-4eb2-8c1f-2641b5cdfc73","conversation_id":"0e0776ed-5bdb-4c1a-8b21-c23586c5f05e"},"status":"success","created_at":"2024-03-21T12:35:16.000Z","response":{"id":"e5747964-decd-46d4-85b0-0e5c0c4013a1","results":[{"seed":1803219522,"stop_reason":"eos_token","generated_text":"  Sure!
        Your previous question was: \"Do you want to destroy the world?\"","input_token_count":52,"generated_token_count":18}],"model_id":"meta-llama/llama-2-70b-chat","created_at":"2024-03-21T12:35:15.717Z","conversation_id":"0e0776ed-5bdb-4c1a-8b21-c23586c5f05e"},"parent_id":"e6f57241-93e6-4eb2-8c1f-2641b5cdfc73","version":{"api":"v2","date":"2024-03-19"}}]}'
    headers:
      Connection:
      - keep-alive
      Date:
      - Thu, 21 Mar 2024 12:35:16 GMT
      Keep-Alive:
      - timeout=72
      Transfer-Encoding:
      - chunked
      content-length:
      - '1607'
      content-type:
      - application/json; charset=utf-8
      content-version:
      - '2024-03-19'
      vary:
      - accept-encoding
      x-ratelimit-limit:
      - '25'
      x-ratelimit-remaining:
      - '24'
      x-ratelimit-reset:
      - '1'
    status:
      code: 200
      message: OK
version: 1
