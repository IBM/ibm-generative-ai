interactions:
- request:
    body: '{"messages": [{"content": "Do you want to destroy the world?", "role":
      "user"}], "model_id": "meta-llama/llama-2-70b-chat"}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '123'
      content-type:
      - application/json
    method: POST
    uri: https://api.com/v2/text/chat?version=2024-01-10
  response:
    body:
      string: '{"id":"168f5d54-10b4-4e03-8bad-be8a6ffae40c","model_id":"meta-llama/llama-2-70b-chat","created_at":"2024-02-24T21:35:25.086Z","results":[{"generated_text":"  No,
        I do not want to destroy the world. As a responsible AI language model,","generated_token_count":20,"input_token_count":18,"stop_reason":"max_tokens","seed":3727522063}],"conversation_id":"9ccc9333-5850-43ed-a95f-0f6afec3aa52"}'
    headers:
      Connection:
      - keep-alive
      Date:
      - Sat, 24 Feb 2024 21:35:25 GMT
      Keep-Alive:
      - timeout=72
      content-length:
      - '389'
      content-type:
      - application/json; charset=utf-8
      content-version:
      - '2024-01-10'
      vary:
      - accept-encoding
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
    method: GET
    uri: https://api.com/v2/requests/chat/9ccc9333-5850-43ed-a95f-0f6afec3aa52?version=2023-11-22
  response:
    body:
      string: '{"results":[{"id":"168f5d54-10b4-4e03-8bad-be8a6ffae40c","duration":1203,"request":{"messages":[{"role":"user","content":"Do
        you want to destroy the world?"}],"model_id":"meta-llama/llama-2-70b-chat","conversation_id":"9ccc9333-5850-43ed-a95f-0f6afec3aa52"},"status":"success","created_at":"2024-02-24T21:35:25.000Z","response":{"id":"168f5d54-10b4-4e03-8bad-be8a6ffae40c","results":[{"seed":3727522063,"stop_reason":"max_tokens","generated_text":"  No,
        I do not want to destroy the world. As a responsible AI language model,","input_token_count":18,"generated_token_count":20}],"model_id":"meta-llama/llama-2-70b-chat","created_at":"2024-02-24T21:35:25.086Z","conversation_id":"9ccc9333-5850-43ed-a95f-0f6afec3aa52"},"version":{"api":"v2","date":"2024-01-10"}}]}'
    headers:
      Connection:
      - keep-alive
      Date:
      - Sat, 24 Feb 2024 21:35:25 GMT
      Keep-Alive:
      - timeout=72
      content-length:
      - '763'
      content-type:
      - application/json; charset=utf-8
      content-version:
      - '2023-11-22'
      vary:
      - accept-encoding
      x-ratelimit-limit:
      - '25'
      x-ratelimit-remaining:
      - '24'
      x-ratelimit-reset:
      - '1'
    status:
      code: 200
      message: OK
- request:
    body: '{"conversation_id": "9ccc9333-5850-43ed-a95f-0f6afec3aa52", "messages":
      [{"content": "What was my previous question?", "role": "user"}], "model_id":
      "meta-llama/llama-2-70b-chat"}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '179'
      content-type:
      - application/json
    method: POST
    uri: https://api.com/v2/text/chat?version=2024-01-10
  response:
    body:
      string: '{"id":"0efd2bdf-f942-49c9-b91f-ef5b62e1e9a7","model_id":"meta-llama/llama-2-70b-chat","created_at":"2024-02-24T21:35:27.502Z","results":[{"generated_text":"  Sure!
        Your previous question was: Do you want to destroy the world?","generated_token_count":17,"input_token_count":52,"stop_reason":"eos_token","seed":3139754148}],"conversation_id":"9ccc9333-5850-43ed-a95f-0f6afec3aa52"}'
    headers:
      Connection:
      - keep-alive
      Date:
      - Sat, 24 Feb 2024 21:35:27 GMT
      Keep-Alive:
      - timeout=72
      content-length:
      - '380'
      content-type:
      - application/json; charset=utf-8
      content-version:
      - '2024-01-10'
      vary:
      - accept-encoding
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
    method: GET
    uri: https://api.com/v2/requests/chat/9ccc9333-5850-43ed-a95f-0f6afec3aa52?version=2023-11-22
  response:
    body:
      string: '{"results":[{"id":"168f5d54-10b4-4e03-8bad-be8a6ffae40c","duration":1203,"request":{"messages":[{"role":"user","content":"Do
        you want to destroy the world?"}],"model_id":"meta-llama/llama-2-70b-chat","conversation_id":"9ccc9333-5850-43ed-a95f-0f6afec3aa52"},"status":"success","created_at":"2024-02-24T21:35:25.000Z","response":{"id":"168f5d54-10b4-4e03-8bad-be8a6ffae40c","results":[{"seed":3727522063,"stop_reason":"max_tokens","generated_text":"  No,
        I do not want to destroy the world. As a responsible AI language model,","input_token_count":18,"generated_token_count":20}],"model_id":"meta-llama/llama-2-70b-chat","created_at":"2024-02-24T21:35:25.086Z","conversation_id":"9ccc9333-5850-43ed-a95f-0f6afec3aa52"},"version":{"api":"v2","date":"2024-01-10"}},{"id":"0efd2bdf-f942-49c9-b91f-ef5b62e1e9a7","duration":878,"request":{"messages":[{"role":"user","content":"What
        was my previous question?"}],"model_id":"meta-llama/llama-2-70b-chat","parent_id":"168f5d54-10b4-4e03-8bad-be8a6ffae40c","conversation_id":"9ccc9333-5850-43ed-a95f-0f6afec3aa52"},"status":"success","created_at":"2024-02-24T21:35:28.000Z","response":{"id":"0efd2bdf-f942-49c9-b91f-ef5b62e1e9a7","results":[{"seed":3139754148,"stop_reason":"eos_token","generated_text":"  Sure!
        Your previous question was: Do you want to destroy the world?","input_token_count":52,"generated_token_count":17}],"model_id":"meta-llama/llama-2-70b-chat","created_at":"2024-02-24T21:35:27.502Z","conversation_id":"9ccc9333-5850-43ed-a95f-0f6afec3aa52"},"parent_id":"168f5d54-10b4-4e03-8bad-be8a6ffae40c","version":{"api":"v2","date":"2024-01-10"}}]}'
    headers:
      Connection:
      - keep-alive
      Date:
      - Sat, 24 Feb 2024 21:35:28 GMT
      Keep-Alive:
      - timeout=72
      Transfer-Encoding:
      - chunked
      content-length:
      - '1602'
      content-type:
      - application/json; charset=utf-8
      content-version:
      - '2023-11-22'
      vary:
      - accept-encoding
      x-ratelimit-limit:
      - '25'
      x-ratelimit-remaining:
      - '24'
      x-ratelimit-reset:
      - '1'
    status:
      code: 200
      message: OK
version: 1
