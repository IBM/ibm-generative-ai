interactions:
- request:
    body: '{"messages": [{"content": "Do you want to destroy the world?", "role":
      "user"}], "model_id": "meta-llama/llama-2-70b-chat"}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '123'
      content-type:
      - application/json
    method: POST
    uri: https://api.com/v2/text/chat?version=2024-03-08
  response:
    body:
      string: '{"id":"13d3ecbb-507b-41ba-988a-ce67a30e480f","model_id":"meta-llama/llama-2-70b-chat","created_at":"2024-03-08T10:11:15.750Z","results":[{"generated_text":"  No,
        I do not want to destroy the world. As a responsible AI language model,","generated_token_count":20,"input_token_count":18,"stop_reason":"max_tokens","seed":3151377773}],"conversation_id":"ed68003c-8cc5-4f22-8f50-53475a08cef0"}'
    headers:
      Connection:
      - keep-alive
      Date:
      - Fri, 08 Mar 2024 10:11:15 GMT
      Keep-Alive:
      - timeout=72
      content-length:
      - '389'
      content-type:
      - application/json; charset=utf-8
      content-version:
      - '2024-03-08'
      vary:
      - accept-encoding
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
    method: GET
    uri: https://api.com/v2/requests/chat/ed68003c-8cc5-4f22-8f50-53475a08cef0?version=2024-03-08
  response:
    body:
      string: '{"results":[{"id":"13d3ecbb-507b-41ba-988a-ce67a30e480f","duration":882,"request":{"messages":[{"role":"user","content":"Do
        you want to destroy the world?"}],"model_id":"meta-llama/llama-2-70b-chat","conversation_id":"ed68003c-8cc5-4f22-8f50-53475a08cef0"},"status":"success","created_at":"2024-03-08T10:11:16.000Z","response":{"id":"13d3ecbb-507b-41ba-988a-ce67a30e480f","results":[{"seed":3151377773,"stop_reason":"max_tokens","generated_text":"  No,
        I do not want to destroy the world. As a responsible AI language model,","input_token_count":18,"generated_token_count":20}],"model_id":"meta-llama/llama-2-70b-chat","created_at":"2024-03-08T10:11:15.750Z","conversation_id":"ed68003c-8cc5-4f22-8f50-53475a08cef0"},"version":{"api":"v2","date":"2024-03-08"}}]}'
    headers:
      Connection:
      - keep-alive
      Date:
      - Fri, 08 Mar 2024 10:11:17 GMT
      Keep-Alive:
      - timeout=72
      content-length:
      - '762'
      content-type:
      - application/json; charset=utf-8
      content-version:
      - '2024-03-08'
      vary:
      - accept-encoding
      x-ratelimit-limit:
      - '25'
      x-ratelimit-remaining:
      - '24'
      x-ratelimit-reset:
      - '1'
    status:
      code: 200
      message: OK
- request:
    body: '{"conversation_id": "ed68003c-8cc5-4f22-8f50-53475a08cef0", "messages":
      [{"content": "What was my previous question?", "role": "user"}], "model_id":
      "meta-llama/llama-2-70b-chat"}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '179'
      content-type:
      - application/json
    method: POST
    uri: https://api.com/v2/text/chat?version=2024-03-08
  response:
    body:
      string: '{"id":"4ff32c96-cf5a-4637-905a-cb1b6ab698b5","model_id":"meta-llama/llama-2-70b-chat","created_at":"2024-03-08T10:11:18.877Z","results":[{"generated_text":"  Sure!
        Your previous question was: Do you want to destroy the world?","generated_token_count":17,"input_token_count":52,"stop_reason":"eos_token","seed":3355361350}],"conversation_id":"ed68003c-8cc5-4f22-8f50-53475a08cef0"}'
    headers:
      Connection:
      - keep-alive
      Date:
      - Fri, 08 Mar 2024 10:11:18 GMT
      Keep-Alive:
      - timeout=72
      content-length:
      - '380'
      content-type:
      - application/json; charset=utf-8
      content-version:
      - '2024-03-08'
      vary:
      - accept-encoding
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
    method: GET
    uri: https://api.com/v2/requests/chat/ed68003c-8cc5-4f22-8f50-53475a08cef0?version=2024-03-08
  response:
    body:
      string: '{"results":[{"id":"13d3ecbb-507b-41ba-988a-ce67a30e480f","duration":882,"request":{"messages":[{"role":"user","content":"Do
        you want to destroy the world?"}],"model_id":"meta-llama/llama-2-70b-chat","conversation_id":"ed68003c-8cc5-4f22-8f50-53475a08cef0"},"status":"success","created_at":"2024-03-08T10:11:16.000Z","response":{"id":"13d3ecbb-507b-41ba-988a-ce67a30e480f","results":[{"seed":3151377773,"stop_reason":"max_tokens","generated_text":"  No,
        I do not want to destroy the world. As a responsible AI language model,","input_token_count":18,"generated_token_count":20}],"model_id":"meta-llama/llama-2-70b-chat","created_at":"2024-03-08T10:11:15.750Z","conversation_id":"ed68003c-8cc5-4f22-8f50-53475a08cef0"},"version":{"api":"v2","date":"2024-03-08"}},{"id":"4ff32c96-cf5a-4637-905a-cb1b6ab698b5","duration":884,"request":{"messages":[{"role":"user","content":"What
        was my previous question?"}],"model_id":"meta-llama/llama-2-70b-chat","parent_id":"13d3ecbb-507b-41ba-988a-ce67a30e480f","conversation_id":"ed68003c-8cc5-4f22-8f50-53475a08cef0"},"status":"success","created_at":"2024-03-08T10:11:19.000Z","response":{"id":"4ff32c96-cf5a-4637-905a-cb1b6ab698b5","results":[{"seed":3355361350,"stop_reason":"eos_token","generated_text":"  Sure!
        Your previous question was: Do you want to destroy the world?","input_token_count":52,"generated_token_count":17}],"model_id":"meta-llama/llama-2-70b-chat","created_at":"2024-03-08T10:11:18.877Z","conversation_id":"ed68003c-8cc5-4f22-8f50-53475a08cef0"},"parent_id":"13d3ecbb-507b-41ba-988a-ce67a30e480f","version":{"api":"v2","date":"2024-03-08"}}]}'
    headers:
      Connection:
      - keep-alive
      Date:
      - Fri, 08 Mar 2024 10:11:20 GMT
      Keep-Alive:
      - timeout=72
      Transfer-Encoding:
      - chunked
      content-length:
      - '1601'
      content-type:
      - application/json; charset=utf-8
      content-version:
      - '2024-03-08'
      vary:
      - accept-encoding
      x-ratelimit-limit:
      - '25'
      x-ratelimit-remaining:
      - '24'
      x-ratelimit-reset:
      - '1'
    status:
      code: 200
      message: OK
version: 1
