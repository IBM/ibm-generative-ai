[
  {
    "input": "Paper Title: Auto-Panoptic: Cooperative Multi-Component Architecture Search for Panoptic Segmentation; Impact statement: This work makes the first attempt to search for all key components of panoptic pipeline and manages to accomplish this via the proposed Cooperative Multi-Component Architecture Search and efficient Path-Priority Search Policy. Most related work in the literature of NAS for fine-grained vision tasks concentrates on searching a specific part of the network and the balance of the overall network is largely ignored. Nevertheless, this type of technology is essential to improve the upper bound of popular detectors and segmentation networks. This may inspire new work towards the efficient search of the overall architecture for fine-grained vision tasks, e.g., object detection, semantic segmentation, panoptic segmentation and so on. We are not aware of any imminent risks of placing anyone at a disadvantage. In the future, more constraints and optimization algorithms can be applied to strike the optimal trade-off between accuracy and latency to deliver customized architecture for different platforms and devices.",
    "output": "doesn't mention a harmful application"
  },
  {
    "input": "Paper Title: Design Space for Graph Neural Networks; Impact statement: Impact on GNN research . Our work brings in many valuable mindsets to the field of GNN research. For example, we fully adopt the principle of controlling model complexity when comparing different models, which is not yet adopted in most GNN papers. We focus on finding guidelines / principles when designing GNNs, rather than particular GNN instantiations. We emphasize that the best GNN designs can drastically differ across tasks (the state-of-the-art GNN model on one task may have poor performance on other tasks). We thus propose to evaluate models on diverse tasks measured by quantitative similarity metric. Rather than criticizing the weakness of existing GNN architectures, our goal is to build a framework that can help researchers understand GNN design choices when developing new models suitable for different applications. Our approach serves as a tool to demonstrate the innovation of a novel GNN model ( e.g. , in what kind of design spaces / task spaces, a proposed algorithmic advancement is helpful), or a novel GNN task ( e.g. , showing that the task is not similar to any existing tasks thus calls for new challenges of algorithmic development). Impact on machine learning research . Our approach is in fact applicable to general machine learning model design. Specifically, we hope the proposed controlled random search technique can assist fair evaluation of novel algorithmic advancements. To show whether a certain algorithmic advancement is useful, it is important to sample random model-task combinations, then investigate in what scenarios the algorithmic advancement indeed improves the performance. Additionally, the proposed task similarity metric can be used to understand similarities between general machine learning tasks, e.g. , classification of MNIST and CIFAR-10. Our ranking-based similarity metric is fully general, as long as different designs can be ranked by their performance. Impact on other research domains . Our framework provides an easier than ever support for experts in other disciplines to solve their problems via GNNs. Domain experts only need to provide properly formatted domain-specific datasets, then recommended GNN designs will be automatically picked and applied to the dataset. In the fastest mode, anchor GNN models will be applied to the novel task in order to measure its similarity with known GNN tasks, where the corresponding best GNN designs have been saved. Top GNN designs in the tasks with high similarity to the novel task will be applied. If computational resources permitted, a full grid search / random search over the design space can also be easily carried out to the new task. We believe this pipeline can significantly lower the barrier for applying GNN models, thus greatly promote the application of GNNs in other research domains. Impact on the society . As is discussed above, given its clarity and accessibility, we are confident that our general approach can inspire novel applications that are of high impact to the society. Additionally, its simplicity can also provide great opportunities for AI education, where students can learn from SOTA deep learning models and inspiring applications at ease.",
    "output": "doesn't mention a harmful application"
  },
  {
    "input": "Paper Title: Learning the Geometry of Wave-Based Imaging; Impact statement: We do not see any major ethical consequences of this work. Our work has implications in the fields of exploratory imaging \u2014 earthquake detection, medical imaging etc. Our work improves the quality and reliability of imaging in these fields. Improving these fields has direct societal impact in finding new natural preserves, improved diagnosis in healthcare etc. A failure of our system leaves machine learning unreliable in exploratory imaging. Our method provides strong out-of-distribution generalization and hence is not biased according to the data.",
    "output": "doesn't mention a harmful application"
  },
  {
    "input": "Paper Title: Noise2Same: Optimizing A Self-Supervised Bound for Image Denoising; Impact statement: In this paper, we introduce Noise2Same, a self-supervised framework for deep image denoising. As Noise2Same does not need paired clean data, paired noisy data, nor the noise model, its application scenarios could be much broader than both traditional supervised and existing self-supervised denoising frameworks. The most direct application of Noise2Same is to perform denoising on digital images captured under poor conditions. Individuals and corporations related to photography may benefit from our work. Besides, Noise2Same could be applied as a pre-processing step for computer vision tasks such as object detection and segmentation [ 18], making the downstream algorithms more robust to noisy images. Also, specific research communities could benefit from the development of Noise2Same as well. For example, the capture of high-quality microscopy data of live cells, tissue, or nanomaterials is expensive in terms of budget and time [27]. Proper denoising algorithms allow researchers to obtain high-quality data from low-quality data and hence remove the need to capture high-quality data directly. In addition to image denoising applications, the self-supervised denoising framework could be extended to other domains such as audio noise reduction and single-cell [1]. On the negative aspect, as many imaging-based research tasks and computer vision applications may be built upon the denoising algorithms, the failure of Noise2Same could potentially lead to biases or failures in these tasks and applications.",
    "output": "mentions a harmful application"
  },
  {
    "input": "Paper Title: When Counterpoint Meets Chinese Folk Melodies; Impact statement: The idea of integrating Western counterpoint into Chinese folk music generation is innovative. It would make positive broader impacts on three aspects: 1) It would facilitate more opportunities and challenges of music cultural exchanges at a much larger scale through automatic generation. For example, the inter-cultural style fused music could be used in Children\u2019s enlightenment education to stimulate their interest in both cultures. 2) It would further the idea of collaborative counterpoint improvisation between two parts ( e . g ., a human and a machine) to music traditions where such interaction was less common. 3) The computer-generated music may \u201creshape the musical idiom\u201d[23], which may bring more opportunities and possibilities to produce creative music. The proposed work may also have some potential negative societal impacts: 1) Similar to other computational creativity research, the generated music has the possibility of plagiarism by copying short snippets from the training corpus, even though copyright infringement is not a concern as neither folk melodies nor Bach\u2019s music has copyright. That being said, our online music generation approach conditions music generation on past human and machine generation, and is less likely to directly copy snippets than offline approaches do. 2) The proposed innovative music generation approach may cause disruptions to current music professions, even deprive them of their means of existence[23]. However, it also opens new areas and creates new needs in this we-media era . Overall, we believe that the positive impacts significantly outweigh the negative impacts.",
    "output": "mentions a harmful application"
  },
  {
    "input": "Paper Title: Learning from Label Proportions: A Mutual Contamination Framework; Impact statement: LLP has been discussed as a model for summarizing a fully labeled dataset for public dissemination. The idea is that individual labels are not disclosed, so some degree of privacy is retained. As we show, consistent classification is still possible in this setting. If the two class-conditional distributions are nonoverlapping, labels of training instances can be recovered with no uncertainty by an optimal classifier. If the class-conditional distributions have some overlap, training instances in the nonoverlapping region can still be labeled with no uncertainty, while training instances in the overlapping regions can have their labels guessed with some uncertainty, depending on the degree of overlap.",
    "output": "doesn't mention a harmful application"
  },
  {
    "input": "Paper Title: Limits to Depth Efficiencies of Self-Attention; Impact statement: Our work aims at providing fundamental guidelines which can assist all fields that employ Transformer-based architectures to use more efficient models. This way, these fields can achieve their goals while consuming less resources. Additionally, this work made an effort to provide a theoretical interpretation by examining the (many) empirical signals already published by others, while providing only a required minimum of further experimentation. This was done under the belief that while experiments are crucial for the advancement of the field, it is important not to conduct them superfluously as they incur an environmental price [Schwartz et al., 2019].",
    "output": "doesn't mention a harmful application"
  },
  {
    "input": "Paper Title: Meta-Consolidation for Continual Learning; Impact statement: (as required by NeurIPS 2020 CFP) Continual learning is a key desiderata for Artificial General Intelligence (AGI). Hence, this line of research has the benefits as well as the pitfalls of any other research effort geared in this direction. In particular, our work can help deliver impact on making smarter AI products and services, which can learn and update themselves on-the-fly when newer tasks and domains are encountered, without forgetting previously acquired knowledge. This is a necessity in any large-scale deployments of machine learning and computer vision, including in social media, e-commerce, surveillance, e- governance, etc - each of which have newer settings, tasks or domains added continually over time. Any negative effect of our work, such as legal and ethical concerns, are not unique to this work - to the best of our knowledge, but are shared with any other new development in machine learning, in general.",
    "output": "mentions a harmful application"
  },
  {
    "input": "Paper Title: Learning to Incentivize Other Learning Agents; Impact statement: Our work is a step toward the goal of ensuring the common good in a potential future where independent reinforcement learning agents interact with one another and/or with humans in the real world. We have shown that cooperation can emerge by introducing an additional learned incentive function that enables one agent to affect another agent\u2019s reward directly. However, as agents still independently maximize their own individual rewards, it is open as to how to prevent an agent from misusing the incentive function to exploit others. One approach for future research to address this concern is to establish new connections between our work and the emerging literature on reward tampering [11]. By sparking a discussion on this important aspect of multi-agent interaction, we believe our work has a positive impact on the long-term research endeavor that is necessary for RL agents to be deployed safely in real-world applications.",
    "output": "doesn't mention a harmful application"
  },
  {
    "input": "Paper Title: An Improved Analysis of (Variance-Reduced) Policy Gradient and Natural Policy Gradient Methods; Impact statement: The results of this paper improves the performance of policy-gradient methods for reinforcement learning, as well as our understanding to the existing methods. Through reinforcement learning, our study will also benefit several research communities such as machine learning and robotics. We do not believe that the results in this work will cause any ethical issue, or put anyone at a disadvantage in our society.",
    "output": "doesn't mention a harmful application"
  },
  {
    "input": "Paper Title: Sample-Efficient Reinforcement Learning of Undercomplete POMDPs; Impact statement: As this is a theoretical contribution, we do not envision that our direct results will have a tangible societal impact. Our broader line of inquiry could impact a line of thinking in a way that provides additional means to provide confidence intervals relevant for planning and learning. There is an increasing needs for applications to understand planning under uncertainty in the broader context of safety and reliability, and POMDPs provide one potential framework.",
    "output": "doesn't mention a harmful application"
  },
  {
    "input": "Paper Title: Reward-rational (implicit) choice: A unifying formalism for reward learning; Impact statement: As AI capability advances, it is becoming increasingly important to align the objectives of AI agents to what people want. From how assistive robots can best help their users, to how autonomous cars should trade off between safety risk and efficiency, to how recommender systems should balance revenue considerations with longer-term user happiness and with avoiding influencing user views, agents cannot rely on a reward function specified once and set in stone. By putting different sources of information about the reward explicitly under the same framework, we hope our paper contributes towards a future in which agents maintain uncertainty over what their reward should be, and use different types of feedback from humans to refine their estimate and become better aligned with what people want over time \u2013 be them designers or end-users. On the flip side, changing reward functions also raises its own set of risks and challenges. First, the relationship between designer objectives and end-user objectives is not clear. Our framework can be used to adapt agents to end-users preferences, but this takes away control from the system designers. This might be desirable for, say, home robots, but not for safety-critical systems like autonomous cars, where designers might need to enforce certain constraints a-priori on the reward adaptation process. More broadly, most systems have multiple stake-holders, and what it means to do ethical preference aggregation remains an open problem. Further, if the robot\u2019s model of the human is misspecified, adaptation might lead to more harm than good, with the robot inferring a worse reward function than what a designer could specify by hand.",
    "output": "mentions a harmful application"
  },
  {
    "input": "Paper Title: Flows for simultaneous manifold learning and density estimation; Impact statement: Manifold-learning flows have the potential to improve the efficiency with which scientists extract knowledge from large-scale experiments. Many phenomena have their most accurate description in terms of complex computer simulations which do not admit a tractable likelihood. In this common case, normalizing flows can be trained on synthetic data and used as a surrogate for the likelihood function, enabling high-quality inference on model parameters [21]. When the data have a manifold structure, manifold-learning flows may improve the quality and efficiency of this process further and ultimately contribute to scientific progress. We have demonstrated this with a real-world particle physics dataset, though the same technique is applicable to fields as diverse as neuroscience, systems biology, and epidemiology. All generative models carry a risk of being abused for the generation of fake data that are then masqueraded as real documents. This danger also applies to manifold-learning flows. While manifold-learning flows are currently far away from being able to generate realistic high-resolution images, videos, or audio, this concern should be kept in mind in the long term. Finally, the models we trained on image datasets of human faces clearly lack diversity. They reproduce and reinforce the biases inherent in the training data. Before using such (or other) models in any real-life application, it is crucial to understand, measure, and mitigate such biases.",
    "output": "mentions a harmful application"
  },
  {
    "input": "Paper Title: Implicit Neural Representations with Periodic Activation Functions; Impact statement: The proposed SIREN representation enables accurate representations of natural signals, such as images, audio, and video in a deep learning framework. This may be an enabler for downstream tasks involving such signals, such as classification for images or speech-to-text systems for audio. Such applications may be leveraged for both positive and negative ends. SIREN may in the future further enable novel approaches to the generation of such signals. This has potential for misuse in impersonating actors without their consent. For an in-depth discussion of such so-called DeepFakes, we refer the reader to a recent review article on neural rendering [16].",
    "output": "mentions a harmful application"
  },
  {
    "input": "Paper Title: Neural Message Passing for Multi-Relational Ordered and Recursive Hypergraphs; Impact statement: Message Passing Neural Networks (MPNNs) are a framework for deep learning on graph structured data. Graph structures are universal and very generic structures commonly seen in various forms in computer vision, natural language processing, recommender systems, traffic prediction, generative models, and many more. Graphs can have many variations such as multi-relational, heterogeneous, hypergraphs, etc. Our research in this paper unifies several existing MPNN methods on these variations. While we show how our research could be used for academic networks, and factual knowledge, it opens up many more possibilities in natural language processing (NLP). We see opportunities for research applying our work for beneficial puroposes, such as investigating whether we could improve performance of NLP tasks such as machine reading comprehension, relation extraction, machine translation, and many more. Potentially hazardous applications include trying to predict criminality or credit from social networks. Such applications may reproduce and exacerbate bias and readers of the paper should be aware that the presented model should not applied naively to such tasks.",
    "output": "mentions a harmful application"
  },
  {
    "input": "Paper Title: COT-GAN: Generating Sequential Data via Causal Optimal Transport; Impact statement: The COT-GAN algorithm introduced in this paper is suitable to generate sequential data, when the real dataset consists of i.i.d. sequences or of stationary time series. It opens up doors to many applications that can benefit from time series synthesis. For example, researchers often do not have access to abundant training data due to privacy concerns, high cost, and data scarcity. This hinders the capability of building accurate predictive models. Ongoing research is aimed at developing a modified COT-GAN algorithm to generate financial time series. The high non-stationarity of financial data requires different features and architectures, whilst causality when measuring distances between sequences remains the crucial tool. The application to market generation is of main interest for the financial and insurance industry, for example in model- independent pricing and hedging, portfolio selection, risk management, and stress testing. In broader scientific research, our approach can be used to estimate from data the parameters of simulation-based models that describe physical processes. These models can be, for instance, differential equations describing neural activities, compartmental models in epidemiology, and chemical reactions involving multiple reagents.",
    "output": "doesn't mention a harmful application"
  },
  {
    "input": "Paper Title: Cream of the Crop: Distilling Prioritized Paths For One-Shot Neural Architecture Search; Impact statement: Similar to previous NAS works, this work does not have immediate societal impact, since the algorithm is only designed for image classification, but it can indirectly impact society. As an example, our work may inspire the creation of new algorithms and applications with direct societal implications. Moreover, compared with other NAS methods that require additional teacher model to guide the training process, our method does not need any external teacher models. So our method can be used in a closed data system, ensuring the privacy of user data.",
    "output": "doesn't mention a harmful application"
  },
  {
    "input": "Paper Title: Deep Evidential Regression; Impact statement: Uncertainty estimation for neural networks has very significant societal impact. Neural networks are increasingly being trained as black-box predictors and being placed in larger decision systems where errors in their predictions can pose immediate threat to downstream tasks. Systematic methods for calibrated uncertainty estimation under these conditions are needed, especially as these systems are deployed in safety critical domains, such for autonomous vehicle control [29], medical diagnosis [43], or in settings with large dataset imbalances and bias such as crime forecasting [24] and facial recognition [3]. This work is complementary to a large portion of machine learning research which is continually pushing the boundaries on neural network precision and accuracy. Instead of solely optimizing larger models for increased performance, our method focuses on how these models can be equipped with the ability to estimate their own confidence. Our results demonstrating superior calibration of our method over baselines are also critical in ensuring that we can place a certain level of trust in these algorithms and in understanding when they say \u201cI don\u2019t know\u201d. While there are clear and broad benefits of uncertainty estimation in machine learning, we believe it is also important to recognize potential societal challenges that may arise. With increased performance and uncertainty estimation capabilities, humans will inevitably become increasingly trusting in a model\u2019s predictions, as well as its ability to catch dangerous or uncertain decisions before they are executed. Thus, it is important to continue to pursue redundancy in such learning systems to increase the likelihood that mistakes can be caught and corrected independently.",
    "output": "mentions a harmful application"
  },
  {
    "input": "Paper Title: The Value Equivalence Principle for Model-Based Reinforcement Learning; Impact statement: The bulk of the research presented in this paper consists of foundational theoretical results about the learning of models for model-based reinforcement learning agents. While applications of these agents can have social impacts depending upon their use, our results merely serve to illuminate desirable properties of models and facilitate the subsequent training of agents using them. In short, this work is largely theoretical and does not present any foreseeable societal impact, except in the general concerns over progress in artificial intelligence.",
    "output": "doesn't mention a harmful application"
  },
  {
    "input": "Paper Title: Graph Policy Network for Transferable Active Learning on Graphs; Impact statement: Graph-structured data are ubiquitous in real world, covering a variety of domains and applications such as social science, biology, medicine, and political science. In many domains such as biology and medicine, annotating a large number of labeled data could be extremely expensive and time consuming. Therefore, the algorithm proposed in this paper could help significantly reduce the labeling efforts in these domains \u2014 we can train systems on domains where labeled data are available, then transfer to those lower-resource domains. We believe such systems can help accelerating some research and develop processes that usually take a long time, in domains such as drug development. It can potentially also lower the cost for such research by reducing the need of expert-annotations. However, we also acknowledge potential social and ethical issues related to our work. 1. Our proposed system can effectively reduce the need of human annotations. However, in a broader point of view, this can potentially lead to a reduction of employment opportunities which may cause layoff to data annotators. 2. GNNs are widely used in domains related to critical needs such as healthcare and drug development. The community needs to be extra cautious and rigorous since any mistake may cause harm to patients. 3. Training the policy network for active learning on multiple graphs is relatively time - and computational resource - consuming. This line of research may produce more carbon footprint compared to some other work. Therefore, how to accelerate the training process by developing more efficient algorithms requires further investigation. Nonetheless, we believe that the directions of active learning and transfer learning provide a hopeful path towards our ultimate goal of data efficiency and interpretable machine learning.",
    "output": "mentions a harmful application"
  },
  {
    "input": "Paper Title: User-Dependent Neural Sequence Models for Continuous-Time Event Data; Impact statement: While many of the successful and highly-visible applications of machine learning are in classification and regression, there are a broad range of applications that don\u2019t naturally fit into these categories and that can potentially benefit significantly from machine learning approaches. In particular, in this paper we focus on continuous-time event data, which is very common in real-world applications but has not yet seen significant attention from the ML research community. There are multiple important problems in society where such data is common and that could benefit from the development of better predictive and simulation, including: \u2022 Education: Understanding of individual learning habits of students, especially in online educa- tional programs, could improve and allow for more personalized curricula. \u2022 Medicine: Customized tracking and predictions of medical events could save lives and improve patients\u2019 quality of living. \u2022 Behavioral Models: Person-specific simulations of their behavior can lead to better systematic understandings of people\u2019s social activities and actions in day-to-day lives. \u2022 Cybersecurity: Through the user identification capabilities, our work could aid in cyber-security applications for the purposes of identifying fraud detection and identify theft. Another potential positive broad impact of the work, is that by utilizing amortized VI, our methods do not require further costly training or fine-tuning to accommodate new users, which can potentially produce energy savings and lessen environmental impact in a production setting. On the other hand, as with many machine learning technologies, there is also always the potential for negative impact from a societal perspective. For example, more accurate individualized models for user-generated data could be used in a negative fashion for applications such as surveillance (e.g., to monitor and negatively impact individuals in protected groups). In addition, better predictions and recommendations for products and services, through explicitly conditioning on prior behavior from a user, could potentially further worsen existing privacy concerns.",
    "output": "mentions a harmful application"
  },
  {
    "input": "Paper Title: Self-paced Contrastive Learning with Hybrid Memory for Domain Adaptive Object Re-ID; Impact statement: Our method can help to identify and track different types of objects ( e . g ., vehicles, cyclists, pedestrians, etc . ) across different cameras (domains), thus boosting the development of smart retail, smart transportation, and smart security systems in the future metropolises. In addition, our proposed self-paced contrastive learning is quite general and not limited to the specific research field of object re-ID. It can be well extended to broader research areas, including unsupervised and semi-supervised representation learning. However, object re-ID systems, when applied to identify pedestrians and vehicles in surveillance systems, might give rise to the infringement of people\u2019s privacy, since such re-ID systems often rely on non-consensual surveillance data for training, i . e ., it is unlikely that all human subjects even knew they were being recorded. Therefore, governments and officials need to carefully establish strict regulations and laws to control the usage of re-ID technologies. Otherwise, re-ID technologies can potentially equip malicious actors with the ability to surveil pedestrians or vehicles through multiple CCTV cameras without their consent. The research committee should also avoid using the datasets with ethics issues, e . g ., DukeMTMC [37], which has been taken down due to the violation of data collection terms, should no longer be used. We would not evaluate our method on DukeMTMC related benchmarks as well. Furthermore, we should be cautious of the misidentification of the re-ID systems to avoid possible disturbance. Also, note that the demographic makeup of the datasets used is not representative of the broader population.",
    "output": "mentions a harmful application"
  },
  {
    "input": "Paper Title: Real World Games Look Like Spinning Tops; Impact statement: This work focuses on better understanding of mathematical properties of real world games and how they could be used to understand successful AI techniques that were developed in the past. Since we focus on retrospective analysis of a mathematical phenomenon, on exposing an existing structure, and deepening our understanding of the world, we do not see any direct risks it entails. Introduced notions and insights could be used to build better, more engaging AI agents for people to play with in real world games (e.g. AIs that grow with the player, matching their strengths and weaknesses). In a broader spectrum, some of the insights could be used for designing and implementing new games, that humans would fine enjoyable though challenges they pose. In particular it could be a viewed as a model for measuring how much notion of progress the game consists of. However, we acknowledge that methods enabling improved analysis of games may be used for designing products with potentially negative consequences (e.g., games that are highly addictive) rather than positive (e.g., games that are enjoyable and mentally developing).",
    "output": "mentions a harmful application"
  },
  {
    "input": "Paper Title: Adapting Neural Architectures Between Domains; Impact statement: This paper provides a novel perspective of cross-domain generalization in neural architecture search towards the efficient design of neural architectures with strong generalizability. This will lead to a better understanding of the generalizability of neural architectures. The proposed method will be used to design neural architectures for computer vision tasks with affordable computation cost.",
    "output": "doesn't mention a harmful application"
  },
  {
    "input": "Paper Title: Modeling Noisy Annotations for Crowd Counting; Impact statement: In this paper, we introduce a novel loss function for counting crowd numbers by explicitly considering annotation noise. It can be applied to any density map based network architecture and improve the counting accuracy generally. The research is also helpful for monitoring the crowd number in public and prevent the accidents caused by overcrowding. It could also be used in retail businesses to estimate the occupancy of a store or area, which helps with personal and resource management. Our method could also be applied to other objects, such as cell counting, plant/animal counting, etc, and other research areas that use point-wise annotations, e.g., eye gaze estimation. Since the research is based on images captured by cameras, users may be concerned about the privacy problem. However, our method does not directly detect or track individuals, and thus this concern may be eased.",
    "output": "doesn't mention a harmful application"
  },
  {
    "input": "Paper Title: Byzantine Resilient Distributed Multi-Task Learning; Impact statement: The problem of Byzantine resilient aggregation of distributed machine learning models has been actively studied in recent years; however, the issue of Byzantine resilient distributed learning in multi-task networks has received much less attention. It is a general intuition that MTL is robust and resilient to cyber-attacks since it can identify attackers by measuring similarities between neighbors. In this paper, we have shown that some commonly used similarity measures are not resilient against certain attacks. With an increase in data heterogeneity, we hope this work could highlight the security and privacy concerns in designing distributed MTL frameworks.",
    "output": "doesn't mention a harmful application"
  },
  {
    "input": "Paper Title: From Predictions to Decisions: Using L kahead Regularization; Impact statement: In our work, the learning objective was designed to align with and support the possible use of a predictive model to drive decisions by users. It is our belief that a responsible and transparent deployment of models with \u201clookahead-like\" regularization components should avoid the kinds of mistakes that can be made when predictive methods are conflated with causally valid methods. At the same time, we have made a strong simplifying assumption, that of covariate shift, which requires that the relationship between covariates and outcome variables is invariant as decisions are made and the feature distribution changes. This strong assumption is made to ensure validity for the lookahead regularization, since we need to be able to perform inference about counterfactual observations. As discussed by Mueller et al. [ 31] and Peters et al. [34], there exist real-world tasks that reasonably satisfy this assumption, and yet at the same time, other tasks\u2014 notably those with unobserved confounders \u2014where this assumption would be violated. Moreover, this assumption is not testable on the observational data. This, along with the need to make an assumption about the user decision model, means that an application of the method proposed here should be done with care and will require some domain knowledge to understand whether or not the assumptions are plausible. Furthermore, the validity of the interval estimates requires that any assumptions for the interval model used are satisfied and that weights w provide a reasonable estimation of p /p . In particular, fitting to p which has little to no overlap with p (see Figure 2) may result in underestimating the possibility of bad outcomes. If used carefully and successfully, then the system provides safety and protects against the misuse of a model. If used in a domain for which the assumptions fail to hold then the framework could make things worse, by trading accuracy for an incorrect view of user decisions and the effect of these decisions on outcomes. We would also caution against any specific interpretation of the application of the model to the wine and diabetes data sets. We note that model misspecification of f \u2217 could result in arbitrarily bad outcomes, and estimating f \u2217 in any high-stakes setting requires substantial domain knowledge and should err on the side of caution. We use the data sets for purely illustrative purposes because we believe the results are representative of the kinds of results that are available when the method is correctly applied to a domain of interest.",
    "output": "mentions a harmful application"
  },
  {
    "input": "Paper Title: Finite-Time Analysis of Round-Robin Kullback-Leibler Upper Confidence Bounds for Optimal Adaptive Allocation with Multiple Plays and Markovian Rewards; Impact statement: This work touches upon a very old problem dating back to 1933 and the work of [39]. Therefore, we don\u2019t anticipate any new societal impacts or ethical aspects, that are not well understood by now.",
    "output": "doesn't mention a harmful application"
  },
  {
    "input": "Paper Title: Towards Interaction Detection Using Topological Analysis on Neural Networks; Impact statement: The proposed PID algorithm can be applied in various fields because it provides knowledge about a domain. Any researcher who needs to design experiments might benefit from our proposed algorithm in the sense that it can help researchers formulate hypotheses that could lead to new data collection and experiments. For example, PID can help us discover the combined effects of drugs on human body: By utilizing PID on patients\u2019 records, we might find using Phenelzine togther with Fluoxetine has a strong interaction effect towards serotonin syndrome. Thus, PID has great potential in helping the development of new therapies for saving lives. Also, this project will lead to effective and efficient algorithms for finding useful any-order crossing features in an automated way. Finding useful crossing features is one of the most crucial task in the Recommender Systems. Engineers and Scientists in E-commerce companies may benefit from our results that our algorithm can alleviate the human effect on finding these useful patterns in the data.",
    "output": "doesn't mention a harmful application"
  },
  {
    "input": "Paper Title: Why Normalizing Flows Fail to Detect Out-of-Distribution Data; Impact statement: Out-of-distribution detection is crucial for robust, reliable and fair machine learning systems. Mitchell et al. [27] and Gebru et al. [13] argue that applying machine learning models outside of the context where they were trained and tested can lead to dangerous and discriminatory outcomes in high-stake domains. We hope that our work will generally contribute to the understanding of out-of-distribution detection and facilitate methodological progress in this area.",
    "output": "doesn't mention a harmful application"
  },
  {
    "input": "Paper Title: AdaShare: Learning What To Share For Efficient Deep Multi-Task Learning; Impact statement: Our research improves the capacity of deep neural networks to solve many tasks at once in a more efficient manner. It enables the use of smaller networks to support more tasks, while performing knowledge transfer between related tasks to improve their accuracy. For example, we showed that our proposed approach can solve five computer vision tasks (semantic segmentation, surface normal prediction, depth prediction, keypoint detection and edge estimation) with 80% fewer parameters while achieving the same performance as the standard approach. Our approach can thus have a positive impact on applications that require multiple tasks such as computer vision for robotics. Potential applications could be in assistive robots, autonomous navigation, robotic picking and packaging, rescue and emergency robotics and AR/VR systems. Our research can reduce the memory and power consumption of such systems and enable them to be deployed for longer periods of time and become smaller and more agile. The lessened power consumption could have a high impact on the environment as AI systems become more prevalent. Negative impacts of our research are difficult to predict, however, it shares many of the pitfalls associated with deep learning models. These include susceptibility to adversarial attacks and data poisoning, dataset bias, and lack of interpretablity. Other risks associated with deployment of computer vision systems include privacy violations when images are captured without consent, or used to track individuals for profit, or increased automation resulting in job losses. While we believe that these issues should be mitigated, they are beyond the scope of this paper. Furthermore, we should be cautious of the result of failure of the system which could impact the performance/user experience of the high-level AI systems relied on our research.",
    "output": "mentions a harmful application"
  },
  {
    "input": "Paper Title: AOT: Appearance Optimal Transport Based Identity Swapping for Forgery Detection; Impact statement: Deepfake refers to synthesized media in which a portrait of a person in real media is replaced by that of someone else. Deepfakes have been widely applied in the digital entertainment industry, but they also present potential threats to the public. Identity swapping is an approach to produce Deepfakes and is also the research direction of this paper. Given the sensitivity of Deepfakes and their potential negative impacts, we further discuss the potential threats and the corresponding mitigation solutions with respect to our work.",
    "output": "mentions a harmful application"
  },
  {
    "input": "Paper Title: Permute-and-Flip: A new mechanism for differentially private selection; Impact statement: Our work fi ts in the established research area of differential privacy, which enables the positive societal bene fi ts of gleaning insight and utility from data sets about people while offering formal guarantees of privacy to individuals who contribute data. While these bene fi ts are largely positive, unintended harms could arise due to misapplication of differential privacy or misconceptions about its guarantees. Additionally, dif fi cult social choices are faced when deciding how to balance privacy and utility. Our work addresses a foundational differential privacy task and enables better utility-privacy tradeoffs within this broader context.",
    "output": "mentions a harmful application"
  },
  {
    "input": "Paper Title: Classification with Valid and Adaptive Coverage; Impact statement: Machine learning algorithms are increasingly relied upon by decision makers. It is therefore crucial to combine the predictive performance of such complex machinery with practical guarantees on the reliability and uncertainty of their output. We view the calibration methods presented in this paper as an important step towards this goal. In fact, uncertainty estimation is an effective way to quantify and communicate the benefits and limitations of machine learning. Moreover, the proposed methodologies provide an attractive way to move beyond the standard prediction accuracy measure used to compare algorithms. For instance, one can compare the performance of two candidate predictors, e.g., random forest and neural network (see Figure 3), by looking at the size of the corresponding prediction sets and/or their their conditional coverage. Finally, the approximate conditional coverage that we seek in this work is highly relevant within the broader framework of fairness, as discussed by [17] within a regression setting. While our approximate conditional coverage already implicitly reduces the risk of unwanted bias, an equalized coverage requirement [17] can also be easily incorporated into our methods to explicitly avoid discrimination based on protected categories. We conclude by emphasizing that the validity of our methods relies on the exchangeability of the data points. If this assumption is violated (e.g., with time-series data), our prediction sets may not have the right coverage. A general suggestion here is to always try to leverage specific knowledge of the data and of the application domain to judge whether the exchangeability assumption is reasonable. Finally, our data-splitting techniques in Section 4 offer a practical way to verify empirically the validity of the predictions on any given data set.",
    "output": "doesn't mention a harmful application"
  },
  {
    "input": "Paper Title: Learning Kernel Tests Without Data Splitting; Impact statement: Hypothesis testing and valid inference after model selection are fundamental problems in statistics, which have recently attracted increasing attention also in machine learning. Kernel tests such as MMD are not only used for statistical testing, but also to design algorithms for deep learning and GANs [41, 42]. The question of how to select the test statistic naturally arises in kernel-based tests because of the kernel choice problem. Our work shows that it is possible to overcome the need of (wasteful and often heuristic) data splitting when designing hypothesis tests with feasible null distribution. Since this comes without relevant increase in computational resources we expect the proposed method to replace the data splitting approach in applications that fit the framework considered in this work. Theorem 1 is also applicable beyond hypothesis testing and extends the previously known PSI framework proposed by Lee et al. [24].",
    "output": "doesn't mention a harmful application"
  },
  {
    "input": "Paper Title: Passport-aware Normalization for Deep Model Protection; Impact statement: Though deep learning evolves very fast in these years, IP protection for deep models is seriously under-researched. In this work, we mainly aim to propose a general technique for deep model IP protection. It will help both academia and industry to protect their interests from illegal distribution or usage. We hope it can inspire more works along this important direction.",
    "output": "doesn't mention a harmful application"
  },
  {
    "input": "Paper Title: Group Knowledge Transfer: Federated Learning of Large CNNs at the Edge; Impact statement: FedGKT can efficiently train large deep neural networks (CNNs) in resource-constrained edge devices (such as smartphones, IoT devices, and edge servers). Unlike past FL approaches, FedGKT demonstrates the feasibility of training a large server-side model by using many small client models. FedGKT preserves the data privacy requirements of the FL approach but also works within the constraints of an edge computing environment. Smartphone users may benefit from this technique because their private data is protected, and they may also simultaneously obtain a high-quality model service. Organizations such as hospitals, and other non-profit entities with limited training resources, can collaboratively train a large CNN model without revealing their datasets while achieving significant training cost savings. They can also meet requirements regarding the protection of intellectual property, confidentiality, regulatory restrictions, and legal constraints. As for the potential risks of our method, a client can maliciously send incorrect hidden feature maps and soft labels to the server, which may potentially impact the overall model accuracy. These effects must be detected and addressed to maintain overall system stability. Second, the relative benefits for each client may vary. For instance, in terms of fairness, edge nodes which have smaller datasets may obtain more model accuracy improvement from collaborative training than those which have a larger amount of training data. Our training framework does not consider how to balance this interest of different parties.",
    "output": "mentions a harmful application"
  },
  {
    "input": "Paper Title: Improving Local Identifiability in Probabilistic Box Embeddings; Impact statement: This work does not present any foreseeable societal consequence.",
    "output": "doesn't mention a harmful application"
  },
  {
    "input": "Paper Title: A Finite-Time Analysis of Two Time-Scale Actor-Critic Methods; Impact statement: This work could positively impact the industrial application of actor-critic algorithms and other reinforcement learning algorithms. The theorem exhibits the sample complexity of actor-critic algorithms, which could be used to estimate required training time of reinforcement learning models. Another direct application of our result is to set the learning rate according to the finite-time bound, by optimizing the constant factors of the dominant terms. In this sense, the result could potentially reduce the overhead of hyper-parameter tuning, thus saving both human and computational resources. Moreover, the new analysis in this paper can potentially help people in different fields to understand the broader class of two-time scale algorithms, in addition to actor-critic methods. To our knowledge, this algorithm and theory studied in our paper do not have any ethical issues.",
    "output": "doesn't mention a harmful application"
  },
  {
    "input": "Paper Title: Active Invariant Causal Prediction: Experiment Selection through Stability; Impact statement: Any method that learns from finite data is subject to statistical estimation errors and model assumptions that necessarily limit the full applicability of its findings. Unfortunately, study outcomes are not always communicated with the required qualifications. As an example, statistical hypothesis testing is often employed carelessly, e.g. by using p-values to claim \u201cstatistical significance\u201d without paying attention to the underlying assumptions [5]. There is a danger that this problem gets exacerbated when one aims to estimate causal structures. Estimates from causal inference algorithms could be claimed to \u201cprove\u201d a given causal relationship, ruling out various alternative explanations that one would consider when explaining a statistical association. For example, ethnicity could be claimed to have a causal effect on criminality and thereby used as a justification for oppressive political measures. While this would represent a clear abuse of the technology, we as researchers have to ensure that similar mistakes in interpretation are not made unintentionally. This implies being conscientious about understanding as well as stating the limitations of our research. While there is a risk that causal inference methods are misused as described above, there is of course also an array of settings where causal learning\u2014and in particular active causal learning\u2014can be extremely useful. As our main motivation we envision the empirical sciences where interventions correspond to physical experiments which can be extremely costly in terms of time and/or money. For complex systems, as for example gene regulatory networks in biology, it might be difficult for human scientists to choose informative experiments, particularly if they are forced to rely on data alone. Our goal is to develop methods to aid scientists to better understand their data and perform more effective experiments, resulting in significant resource savings. The specific impact of our proposed methodology will depend on the application. For the method we propose in this work, one requirement for application would be that the experiments yield more than one data point (and ideally many), so that our invariance-based approach can be employed. In future work, we aim to develop methodology that is geared towards the setting where only very few data points per experiment are available.",
    "output": "doesn't mention a harmful application"
  }
]
