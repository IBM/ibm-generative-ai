# generated by datamodel-codegen:
#   filename:  2024-03-22_openapi_schema

from __future__ import annotations

from datetime import date
from enum import Enum
from typing import Any, Literal, Optional, Union

import deprecated
from pydantic import AwareDatetime, Field, RootModel, computed_field, field_validator

from genai._types import ApiBaseModel
from genai._utils.deprecated_schema_import import _print_deprecation_warning


class ApiKeyResult(ApiBaseModel):
    created_at: AwareDatetime
    generated_at: AwareDatetime
    last_used_at: Optional[AwareDatetime] = None
    value: str


class BaseErrorExtension(ApiBaseModel):
    code: str
    state: Optional[dict[str, Any]] = None


class BaseErrorResponse(ApiBaseModel):
    error: str
    extensions: BaseErrorExtension
    message: str
    status_code: int


class BaseMessage(ApiBaseModel):
    content: str
    files: Optional[list[MessageFile]] = None
    role: ChatRole

    @computed_field
    @deprecated.deprecated(reason="'file_ids' property is deprecated, use 'files' instead!")
    def file_ids(self) -> Optional[list[str]]:
        return [file.id for file in self.files] if self.files is not None else None


class BaseTokens(ApiBaseModel):
    logprob: Optional[Union[float, str]] = None
    rank: Optional[int] = None
    text: Optional[str] = None
    top_tokens: Optional[list[GeneratedToken]] = None


class ChatRole(str, Enum):
    USER = "user"
    SYSTEM = "system"
    ASSISTANT = "assistant"


class ConcurrencyLimit(ApiBaseModel):
    limit: int
    remaining: int


class DecodingMethod(str, Enum):
    GREEDY = "greedy"
    SAMPLE = "sample"


class Extensions(BaseErrorExtension):
    code: Literal["INVALID_INPUT"] = "INVALID_INPUT"


class Extensions1(BaseErrorExtension):
    code: Literal["INTERNAL_SERVER_ERROR"] = "INTERNAL_SERVER_ERROR"


class Extensions2(BaseErrorExtension):
    code: Literal["NOT_FOUND"] = "NOT_FOUND"


class Extensions3(BaseErrorExtension):
    code: Literal["TOO_MANY_REQUESTS"] = "TOO_MANY_REQUESTS"


class Extensions4(BaseErrorExtension):
    code: Literal["AUTH_ERROR"] = "AUTH_ERROR"


class Extensions5(BaseErrorExtension):
    code: Literal["SERVICE_UNAVAILABLE"] = "SERVICE_UNAVAILABLE"


class FileDescendant(ApiBaseModel):
    id: str


class FileFormat(ApiBaseModel):
    id: int
    name: str


class FileListSortBy(str, Enum):
    NAME = "name"
    CREATED_AT = "created_at"


class FilePurpose(str, Enum):
    TUNE = "tune"
    TEMPLATE = "template"
    TUNE_IMPORT = "tune_import"
    EXTRACTION = "extraction"


class FileResult(ApiBaseModel):
    bytes: int
    created_at: AwareDatetime
    descendants: Optional[list[FileDescendant]] = None
    file_formats: Optional[list[FileFormat]] = None
    file_name: str
    id: str
    origin: Optional[FileDescendant] = None
    purpose: FilePurpose
    storage_provider_location: StorageProviderLocation
    updated_at: AwareDatetime


class FolderResult(ApiBaseModel):
    created_at: AwareDatetime
    id: str
    name: str
    prompt_ids: Optional[list[str]] = None


class GeneratedToken(ApiBaseModel):
    logprob: Optional[Union[float, str]] = None
    text: Optional[str] = None


class HAPOptions(ApiBaseModel):
    send_tokens: Optional[bool] = False
    threshold: Optional[float] = Field(0.75, gt=0.0, lt=1.0)


class Input(RootModel[list[Any]]):
    root: list[Any] = Field(..., max_length=20)


class InternalServerErrorResponse(BaseErrorResponse):
    extensions: Extensions1
    status_code: Literal[500] = 500


class LengthPenalty(ApiBaseModel):
    decay_factor: Optional[float] = Field(None, gt=1.0, title="Decay factor")
    """
    Represents the factor of exponential decay and must be > 1.0. Larger values correspond to more aggressive decay.
    """
    start_index: Optional[int] = Field(None, ge=1, title="Start index")
    """
    A number of generated tokens after which this should take effect.
    """


class MessageFile(ApiBaseModel):
    content: Optional[str] = None
    id: Optional[str] = None


class ModelFacet(ApiBaseModel):
    id: str
    name: str
    type: ModelFacetType


class ModelFacetType(str, Enum):
    LANGUAGE = "language"
    INDUSTRY = "industry"
    MODEL_TYPE = "model_type"


class ModelFamily(ApiBaseModel):
    description: Optional[str] = None
    id: int
    name: str
    prompt_example: Optional[str] = None
    short_description: Optional[str] = None
    system_prompt: Optional[str] = None


class ModelIdRetrieveResult(ApiBaseModel):
    description: Optional[str] = None
    developer: Optional[str] = None
    disabled: bool
    id: str
    is_live: bool
    label: str
    model_family: ModelFamily
    name: str
    preferred: bool
    size: str
    source_model_id: Optional[str] = None
    system_prompt: Optional[str] = None
    system_prompt_id: Optional[int] = None
    tags: list[str]
    tasks: list[Tasks]
    token_limits: list[ModelTokenLimits]
    warning: Optional[str] = None


class ModelRetrieveResults(ApiBaseModel):
    facets: Optional[list[ModelFacet]] = None
    id: str
    is_live: bool
    label: str
    name: str
    size: str
    source_model_id: Optional[str] = None
    task_ids: list[str]
    token_limits: list[ModelTokenLimits]
    warning: Optional[str] = None


class ModelTokenLimits(ApiBaseModel):
    beam_width: int
    token_limit: int


class ModelType(str, Enum):
    MODEL = "model"
    TUNE = "tune"


class ModerationHAP(ApiBaseModel):
    input: Optional[ModerationHAPInput] = None
    output: Optional[ModerationHAPOutput] = None

    # TODO: remove in next major release
    @field_validator("input", mode="before")
    @classmethod
    def _validate_input(cls, value: Any):
        if isinstance(value, bool):
            _print_deprecation_warning(
                "(ModerationHAP): passing boolean value to the 'input' parameter is deprecated, use 'ModerationHAPInput' class instead."
            )
            return ModerationHAPInput(enabled=value)
        else:
            return value

    # TODO: remove in next major release
    @field_validator("output", mode="before")
    @classmethod
    def _validate_output(cls, value: Any):
        if isinstance(value, bool):
            _print_deprecation_warning(
                "(ModerationHAP): passing boolean value to the 'output' parameter is deprecated, use 'ModerationHAPOutput' class instead."
            )
            return ModerationHAPOutput(enabled=value)
        else:
            return value

    # TODO: remove in next major release
    def model_post_init(self, __context: Any) -> None:
        deprecated_attrs = {
            name: getattr(self, name) for name in ["threshold", "send_tokens"] if getattr(self, name, None) is not None
        }
        if deprecated_attrs:
            if self.input is None:
                self.input = ModerationHAPInput(enabled=True)
            if self.output is None:
                self.output = ModerationHAPOutput(enabled=True)

            for name, value in deprecated_attrs.items():
                _print_deprecation_warning(
                    f"(ModerationHAP): '{name}' is deprecated! Use 'input' parameter (ModerationHAPInput) / 'output' parameter parameter (ModerationHAPOutput) instead.",
                )
                setattr(self.input, name, value)
                setattr(self.output, name, value)
                delattr(self, name)


class ModerationHAPInput(ApiBaseModel):
    enabled: Optional[bool] = False
    """
    Detects HAP (hateful, abusive, or profane language).
    """
    send_tokens: Optional[bool] = False
    threshold: Optional[float] = Field(0.75, ge=0.01, le=0.99, multiple_of=0.01)
    """
    The higher the number, the more confidence that the sentence contains HAP. The threshold allows you to modify how much confidence is needed for the sentence to be flagged as containing HAP.
    """


class ModerationHAPOutput(ApiBaseModel):
    enabled: Optional[bool] = False
    """
    Detects HAP (hateful, abusive, or profane language).
    """
    send_tokens: Optional[bool] = False
    threshold: Optional[float] = Field(0.75, ge=0.01, le=0.99, multiple_of=0.01)
    """
    The higher the number, the more confidence that the sentence contains HAP. The threshold allows you to modify how much confidence is needed for the sentence to be flagged as containing HAP.
    """


class ModerationImplicitHate(ApiBaseModel):
    input: Optional[ModerationImplicitHateInput] = None
    output: Optional[ModerationImplicitHateOutput] = None

    # TODO: remove in next major release
    @field_validator("input", mode="before")
    @classmethod
    def _validate_input(cls, value: Any):
        if isinstance(value, bool):
            _print_deprecation_warning(
                "(ModerationImplicitHate): passing boolean value to the 'input' parameter is deprecated, use 'ModerationImplicitHateInput' class instead."
            )
            return ModerationImplicitHateInput(enabled=value)
        else:
            return value

    # TODO: remove in next major release
    @field_validator("output", mode="before")
    @classmethod
    def _validate_output(cls, value: Any):
        if isinstance(value, bool):
            _print_deprecation_warning(
                "(ModerationImplicitHate): passing boolean value to the 'output' parameter is deprecated, use 'ModerationImplicitHateOutput' class instead."
            )
            return ModerationImplicitHateOutput(enabled=value)
        else:
            return value

    # TODO: remove in next major release
    def model_post_init(self, __context: Any) -> None:
        deprecated_attrs = {
            name: getattr(self, name) for name in ["threshold", "send_tokens"] if getattr(self, name, None) is not None
        }
        if deprecated_attrs:
            if self.input is None:
                self.input = ModerationImplicitHateInput(enabled=True)
            if self.output is None:
                self.output = ModerationImplicitHateOutput(enabled=True)

            for name, value in deprecated_attrs.items():
                _print_deprecation_warning(
                    f"(ModerationImplicitHate): '{name}' is deprecated! Use 'input' parameter (ModerationImplicitHateInput) / 'output' parameter parameter (ModerationImplicitHateOutput) instead.",
                )
                setattr(self.input, name, value)
                setattr(self.output, name, value)
                delattr(self, name)


class ModerationImplicitHateInput(ApiBaseModel):
    enabled: bool = False
    send_tokens: Optional[bool] = False
    threshold: Optional[float] = Field(0.75, gt=0.0, lt=1.0)


class ModerationImplicitHateOutput(ApiBaseModel):
    enabled: bool = False
    send_tokens: Optional[bool] = False
    threshold: Optional[float] = Field(0.75, gt=0.0, lt=1.0)


class ModerationParameters(ApiBaseModel):
    hap: Optional[ModerationHAP] = None
    social_bias: Optional[ModerationSocialBias] = None

    # TODO: remove in next major release
    def model_post_init(self, __context: Any) -> None:
        for name in ["stigma", "implicit_hate"]:
            if hasattr(self, name):
                _print_deprecation_warning(
                    f'({type(self).__name__}): "{name}" has been deprecated, use "social_bias" instead.'
                )

    # TODO: remove in next major release
    def remove_deprecated(self) -> None:
        """Remove attributes which are not supported anymore"""
        for name in ["stigma", "implicit_hate"]:
            if hasattr(self, name):
                _print_deprecation_warning(
                    f'({type(self).__name__} class): "{name}" has been deprecated, use "social_bias" instead.',
                )
                delattr(self, name)

    # TODO: remove in next major release
    @field_validator("hap", mode="before")
    @classmethod
    def _validate_hap(cls, value: Any):
        if isinstance(value, bool):
            _print_deprecation_warning(
                "(ModerationParameters): passing boolean value to the 'hap' parameter is deprecated, use 'ModerationHAP' class instead."
            )
            return ModerationHAP(input=ModerationHAPInput(enabled=value), output=ModerationHAPOutput(enabled=value))
        else:
            return value

    # TODO: remove in next major release
    @field_validator("social_bias", mode="before")
    @classmethod
    def _validate_social_bias(cls, value: Any):
        if isinstance(value, bool):
            _print_deprecation_warning(
                "(ModerationParameters): passing boolean value to the 'social_bias' parameter is deprecated, use 'ModerationSocialBias' class instead."
            )
            return ModerationSocialBias(
                input=ModerationSocialBiasInput(enabled=value), output=ModerationSocialBiasOutput(enabled=value)
            )
        else:
            return value


class ModerationPosition(ApiBaseModel):
    end: int
    start: int


class ModerationSocialBias(ApiBaseModel):
    input: Optional[ModerationSocialBiasInput] = None
    output: Optional[ModerationSocialBiasOutput] = None


class ModerationSocialBiasInput(ApiBaseModel):
    enabled: Optional[bool] = False
    """
    Detects social bias.
    """
    send_tokens: Optional[bool] = False
    threshold: Optional[float] = Field(0.75, ge=0.01, le=0.99, multiple_of=0.01)
    """
    The higher the number, the more confidence that the sentence contains social bias. The threshold allows you to modify how much confidence is needed for the sentence to be flagged as containing social bias.
    """


class ModerationSocialBiasOutput(ApiBaseModel):
    enabled: Optional[bool] = False
    """
    Detects social bias.
    """
    send_tokens: Optional[bool] = False
    threshold: Optional[float] = Field(0.75, ge=0.01, le=0.99, multiple_of=0.01)
    """
    The higher the number, the more confidence that the sentence contains social bias. The threshold allows you to modify how much confidence is needed for the sentence to be flagged as containing social bias.
    """


class ModerationStigma(ApiBaseModel):
    input: Optional[ModerationStigmaInput] = None
    output: Optional[ModerationStigmaOutput] = None

    # TODO: remove in next major release
    @field_validator("input", mode="before")
    @classmethod
    def _validate_input(cls, value: Any):
        if isinstance(value, bool):
            _print_deprecation_warning(
                "(ModerationStigma): passing boolean value to the 'input' parameter is deprecated, use 'ModerationStigmaInput' class instead."
            )
            return ModerationStigmaInput(enabled=value)
        else:
            return value

    # TODO: remove in next major release
    @field_validator("output", mode="before")
    @classmethod
    def _validate_output(cls, value: Any):
        if isinstance(value, bool):
            _print_deprecation_warning(
                "(ModerationStigma): passing boolean value to the 'output' parameter is deprecated, use 'ModerationStigmaOutput' class instead."
            )
            return ModerationStigmaOutput(enabled=value)
        else:
            return value

    # TODO: remove in next major release
    def model_post_init(self, __context: Any) -> None:
        deprecated_attrs = {
            name: getattr(self, name) for name in ["threshold", "send_tokens"] if getattr(self, name, None) is not None
        }
        if deprecated_attrs:
            if self.input is None:
                self.input = ModerationStigmaInput(enabled=True)
            if self.output is None:
                self.output = ModerationStigmaOutput(enabled=True)

            for name, value in deprecated_attrs.items():
                _print_deprecation_warning(
                    f"(ModerationStigma): '{name}' is deprecated! Use 'input' parameter (ModerationStigmaInput) / 'output' parameter parameter (ModerationStigmaOutput) instead.",
                )
                setattr(self.input, name, value)
                setattr(self.output, name, value)
                delattr(self, name)


class ModerationStigmaInput(ApiBaseModel):
    enabled: bool = False
    send_tokens: Optional[bool] = False
    threshold: Optional[float] = Field(0.75, gt=0.0, lt=1.0)


class ModerationStigmaOutput(ApiBaseModel):
    enabled: bool = False
    send_tokens: Optional[bool] = False
    threshold: Optional[float] = Field(0.75, gt=0.0, lt=1.0)


class ModerationTokens(ApiBaseModel):
    index: Optional[int] = None
    score: Optional[float] = None
    token: Optional[str] = None


class NotFoundResponse(BaseErrorResponse):
    extensions: Extensions2
    status_code: Literal[404] = 404


class _ApiKeyRegenerateCreateParametersQuery(ApiBaseModel):
    version: Literal["2023-11-22"] = "2023-11-22"


class ApiKeyRegenerateCreateResponse(ApiBaseModel):
    result: Optional[ApiKeyResult] = None


class _ApiKeyRetrieveParametersQuery(ApiBaseModel):
    version: Literal["2023-11-22"] = "2023-11-22"


class ApiKeyRetrieveResponse(ApiBaseModel):
    result: Optional[ApiKeyResult] = None


class _BetaTimeSerieForecastingCreateParametersQuery(ApiBaseModel):
    version: Literal["2023-11-22"] = "2023-11-22"


class _BetaTimeSerieForecastingCreateRequest(ApiBaseModel):
    columns: _BetaTimeSerieForecastingCreateRequestColumns
    data: str
    future_data: str
    model_id: str


class BetaTimeSerieForecastingCreateResponse(ApiBaseModel):
    result: _BetaTimeSerieForecastingCreateResult


class _BetaTimeSerieLimitRetrieveParametersQuery(ApiBaseModel):
    version: Literal["2023-11-22"] = "2023-11-22"


class BetaTimeSerieLimitRetrieveResponse(ApiBaseModel):
    result: _BetaTimeSerieLimitRetrieveResult


class _FileCreateParametersQuery(ApiBaseModel):
    version: Literal["2023-12-15"] = "2023-12-15"


class _FileCreateRequest(ApiBaseModel):
    file: bytes
    origin_id: Optional[str] = None
    purpose: FilePurpose


class FileCreateResponse(ApiBaseModel):
    result: FileResult


class _FileIdContentRetrieveParametersQuery(ApiBaseModel):
    version: Literal["2023-11-22"] = "2023-11-22"


class _FileIdDeleteParametersQuery(ApiBaseModel):
    version: Literal["2023-11-22"] = "2023-11-22"


class _FileIdPatchParametersQuery(ApiBaseModel):
    version: Literal["2023-11-22"] = "2023-11-22"


class _FileIdPatchRequest(ApiBaseModel):
    file: bytes


class FileIdPatchResponse(ApiBaseModel):
    result: FileResult


class _FileIdRetrieveParametersQuery(ApiBaseModel):
    version: Literal["2023-12-15"] = "2023-12-15"


class FileIdRetrieveResponse(ApiBaseModel):
    result: FileResult


class _FileRetrieveParametersQuery(ApiBaseModel):
    limit: Optional[int] = Field(100, ge=1, le=100)
    offset: Optional[int] = Field(0, ge=0)
    sort_by: Optional[FileListSortBy] = None
    direction: Optional[SortDirection] = None
    search: Optional[str] = None
    purpose: Optional[FilePurpose] = None
    format_id: Optional[int] = None
    version: Literal["2023-12-15"] = "2023-12-15"


class FileRetrieveResponse(ApiBaseModel):
    results: list[FileResult]
    total_count: int


class _FolderCreateParametersQuery(ApiBaseModel):
    version: Literal["2023-11-22"] = "2023-11-22"


class _FolderCreateRequest(ApiBaseModel):
    name: str


class FolderCreateResponse(ApiBaseModel):
    result: FolderResult


class _FolderIdDeleteParametersQuery(ApiBaseModel):
    version: Literal["2023-11-22"] = "2023-11-22"


class _FolderIdPatchParametersQuery(ApiBaseModel):
    version: Literal["2024-01-10"] = "2024-01-10"


class _FolderIdPatchRequest(ApiBaseModel):
    position: Optional[int] = Field(None, ge=1)


class FolderIdPatchResponse(ApiBaseModel):
    result: FolderResult


class _FolderIdRetrieveParametersQuery(ApiBaseModel):
    version: Literal["2023-11-22"] = "2023-11-22"


class FolderIdRetrieveResponse(ApiBaseModel):
    result: FolderResult


class _FolderIdUpdateParametersQuery(ApiBaseModel):
    version: Literal["2023-11-22"] = "2023-11-22"


class _FolderIdUpdateRequest(ApiBaseModel):
    name: str


class FolderIdUpdateResponse(ApiBaseModel):
    result: FolderResult


class _FolderRetrieveParametersQuery(ApiBaseModel):
    limit: Optional[int] = Field(100, ge=1, le=100)
    offset: Optional[int] = Field(0, ge=0)
    version: Literal["2023-11-22"] = "2023-11-22"


class FolderRetrieveResponse(ApiBaseModel):
    results: list[FolderResult]
    total_count: int


class _ModelIdRetrieveParametersQuery(ApiBaseModel):
    version: Literal["2024-01-30"] = "2024-01-30"


class ModelIdRetrieveResponse(ApiBaseModel):
    result: ModelIdRetrieveResult


class _ModelRetrieveParametersQuery(ApiBaseModel):
    limit: Optional[int] = Field(100, ge=1, le=100)
    offset: Optional[int] = Field(0, ge=0)
    type: Optional[ModelType] = None
    version: Literal["2023-11-22"] = "2023-11-22"


class ModelRetrieveResponse(ApiBaseModel):
    results: list[ModelRetrieveResults]
    total_count: int


class _PromptCreateParametersQuery(ApiBaseModel):
    version: Literal["2024-03-19"] = "2024-03-19"


class _PromptCreateRequest(ApiBaseModel):
    data: Optional[PromptTemplateData] = None
    description: Optional[str] = None
    folder_id: Optional[str] = None
    industry_id: Optional[str] = None
    input: Optional[str] = None
    language_id: Optional[str] = None
    messages: Optional[list[BaseMessage]] = None
    model_id: str
    moderations: Optional[ModerationParameters] = None
    name: str
    output: Optional[str] = Field(None, min_length=1)
    parameters: Optional[TextGenerationParameters] = None
    prompt_id: Optional[str] = None
    task_id: Optional[str] = None
    type: Optional[PromptType] = None


class PromptCreateResponse(ApiBaseModel):
    result: PromptResult


class _PromptIdDeleteParametersQuery(ApiBaseModel):
    version: Literal["2023-11-22"] = "2023-11-22"


class _PromptIdPatchParametersQuery(ApiBaseModel):
    version: Literal["2024-03-19"] = "2024-03-19"


class _PromptIdPatchRequest(ApiBaseModel):
    folder_id: Optional[str] = None
    name: Optional[str] = None
    type: Optional[PromptType] = None


class PromptIdPatchResponse(ApiBaseModel):
    result: PromptResult


class _PromptIdRetrieveParametersQuery(ApiBaseModel):
    version: Literal["2024-03-19"] = "2024-03-19"


class PromptIdRetrieveResponse(ApiBaseModel):
    result: PromptResult


class _PromptIdUpdateParametersQuery(ApiBaseModel):
    version: Literal["2024-03-19"] = "2024-03-19"


class _PromptIdUpdateRequest(ApiBaseModel):
    data: Optional[PromptTemplateData] = None
    description: Optional[str] = None
    folder_id: Optional[str] = None
    industry_id: Optional[str] = None
    input: Optional[str] = None
    language_id: Optional[str] = None
    messages: Optional[list[BaseMessage]] = None
    model_id: str
    moderations: Optional[ModerationParameters] = None
    name: str
    output: Optional[str] = Field(None, min_length=1)
    parameters: Optional[TextGenerationParameters] = None
    prompt_id: Optional[str] = None
    task_id: Optional[str] = None
    type: Optional[PromptType] = None


class PromptIdUpdateResponse(ApiBaseModel):
    result: PromptResult


class _PromptRetrieveParametersQuery(ApiBaseModel):
    limit: Optional[int] = Field(100, ge=1, le=100)
    offset: Optional[int] = Field(0, ge=0)
    sort_by: Optional[PromptListSortBy] = None
    direction: Optional[SortDirection] = None
    search: Optional[str] = None
    task_id: Optional[Union[str, list[str]]] = None
    model_id: Optional[Union[str, list[str]]] = None
    source: Optional[Union[PromptListSource, list[PromptListSource]]] = None
    model_family_id: Optional[float] = None
    industry_id: Optional[Union[str, list[str]]] = None
    prompt_language_id: Optional[Union[str, list[str]]] = None
    model_type_id: Optional[Union[str, list[str]]] = None
    avg_time_min: Optional[int] = None
    avg_time_max: Optional[int] = None
    context_window_min: Optional[int] = None
    context_window_max: Optional[int] = None
    folder_id: Optional[str] = None
    version: Literal["2024-03-19"] = "2024-03-19"


class PromptRetrieveResponse(ApiBaseModel):
    results: list[PromptResult]
    total_count: int


class _RequestChatConversationIdDeleteParametersQuery(ApiBaseModel):
    version: Literal["2023-11-22"] = "2023-11-22"


class _RequestChatConversationIdRetrieveParametersQuery(ApiBaseModel):
    version: Literal["2024-03-19"] = "2024-03-19"


class RequestChatConversationIdRetrieveResponse(ApiBaseModel):
    results: list[RequestChatConversationIdRetrieveResults]


class _RequestIdDeleteParametersQuery(ApiBaseModel):
    version: Literal["2023-11-22"] = "2023-11-22"


class _RequestIdFeedbackCreateParametersQuery(ApiBaseModel):
    version: Literal["2023-11-22"] = "2023-11-22"


class _RequestIdFeedbackCreateRequest(ApiBaseModel):
    categories: Optional[list[RequestFeedbackCategory]] = Field(None, min_length=1)
    comment: Optional[str] = None
    contact_consent: Optional[bool] = False
    vote: Optional[RequestFeedbackVote] = None


class RequestIdFeedbackCreateResponse(ApiBaseModel):
    result: RequestFeedbackResult


class _RequestIdFeedbackRetrieveParametersQuery(ApiBaseModel):
    version: Literal["2023-11-22"] = "2023-11-22"


class RequestIdFeedbackRetrieveResponse(ApiBaseModel):
    result: RequestFeedbackResult


class _RequestIdFeedbackUpdateParametersQuery(ApiBaseModel):
    version: Literal["2023-11-22"] = "2023-11-22"


class _RequestIdFeedbackUpdateRequest(ApiBaseModel):
    categories: Optional[list[RequestFeedbackCategory]] = Field(None, min_length=1)
    comment: Optional[str] = None
    contact_consent: Optional[bool] = False
    vote: Optional[RequestFeedbackVote] = None


class RequestIdFeedbackUpdateResponse(ApiBaseModel):
    result: RequestFeedbackResult


class _RequestRetrieveParametersQuery(ApiBaseModel):
    limit: Optional[int] = Field(100, ge=1, le=100)
    offset: Optional[int] = Field(0, ge=0)
    status: Optional[RequestStatus] = None
    origin: Optional[RequestOrigin] = None
    before: Optional[AwareDatetime] = None
    after: Optional[AwareDatetime] = None
    endpoint: Optional[Union[RequestEndpoint, list[RequestEndpoint]]] = None
    api: Optional[RequestApiVersion] = None
    date_: Optional[date] = Field(None, alias="date")
    version: Literal["2023-11-22"] = "2023-11-22"


class RequestRetrieveResponse(ApiBaseModel):
    results: list[RequestRetrieveResults]
    total_count: int


class _SystemPromptCreateParametersQuery(ApiBaseModel):
    version: Literal["2023-11-22"] = "2023-11-22"


class _SystemPromptCreateRequest(ApiBaseModel):
    content: str
    name: str


class SystemPromptCreateResponse(ApiBaseModel):
    result: SystemPrompt


class _SystemPromptIdDeleteParametersQuery(ApiBaseModel):
    version: Literal["2023-11-22"] = "2023-11-22"


class _SystemPromptIdRetrieveParametersQuery(ApiBaseModel):
    version: Literal["2023-11-22"] = "2023-11-22"


class SystemPromptIdRetrieveResponse(ApiBaseModel):
    result: SystemPrompt


class _SystemPromptIdUpdateParametersQuery(ApiBaseModel):
    version: Literal["2023-11-22"] = "2023-11-22"


class _SystemPromptIdUpdateRequest(ApiBaseModel):
    content: str
    name: str


class SystemPromptIdUpdateResponse(ApiBaseModel):
    result: SystemPrompt


class _SystemPromptRetrieveParametersQuery(ApiBaseModel):
    limit: Optional[int] = Field(100, ge=1, le=100)
    offset: Optional[int] = Field(0, ge=0)
    version: Literal["2023-11-22"] = "2023-11-22"


class SystemPromptRetrieveResponse(ApiBaseModel):
    results: list[SystemPrompt]
    total_count: int


class _TagRetrieveParametersQuery(ApiBaseModel):
    limit: Optional[int] = Field(100, ge=1, le=100)
    offset: Optional[int] = Field(0, ge=0)
    type: Optional[TagType] = None
    version: Literal["2023-11-22"] = "2023-11-22"


class TagRetrieveResponse(ApiBaseModel):
    results: list[Tag]


class _TaskRetrieveParametersQuery(ApiBaseModel):
    tune: Optional[bool] = True
    version: Literal["2023-11-22"] = "2023-11-22"


class TaskRetrieveResponse(ApiBaseModel):
    results: list[Tasks]


class _TextChatCreateParametersQuery(ApiBaseModel):
    version: Literal["2024-03-19"] = "2024-03-19"


class _TextChatCreateRequest(ApiBaseModel):
    conversation_id: Optional[str] = None
    messages: Optional[list[BaseMessage]] = Field(None, min_length=1)
    model_id: Optional[str] = None
    moderations: Optional[ModerationParameters] = None
    parameters: Optional[TextGenerationParameters] = None
    parent_id: Optional[str] = None
    prompt_id: Optional[str] = None
    prompt_template_id: Optional[str] = None
    trim_method: Optional[TrimMethod] = None
    use_conversation_parameters: Optional[bool] = None


class TextChatCreateResponse(ApiBaseModel):
    conversation_id: str
    created_at: Optional[AwareDatetime] = None
    id: Optional[str] = None
    input_parameters: Optional[dict[str, Any]] = None
    model_id: Optional[str] = None
    results: list[TextGenerationResult]


class _TextChatOutputCreateParametersQuery(ApiBaseModel):
    version: Literal["2024-03-19"] = "2024-03-19"


class _TextChatOutputCreateRequest(ApiBaseModel):
    conversation_id: Optional[str] = None
    messages: Optional[list[BaseMessage]] = Field(None, min_length=1)
    model_id: Optional[str] = None
    moderations: Optional[ModerationParameters] = None
    parameters: Optional[TextGenerationParameters] = None
    parent_id: Optional[str] = None
    prompt_id: Optional[str] = None
    prompt_template_id: Optional[str] = None
    trim_method: Optional[TrimMethod] = None
    use_conversation_parameters: Optional[bool] = None


class TextChatOutputCreateResponse(ApiBaseModel):
    result: str


class _TextChatStreamCreateParametersQuery(ApiBaseModel):
    version: Literal["2024-03-19"] = "2024-03-19"


class _TextChatStreamCreateRequest(ApiBaseModel):
    conversation_id: Optional[str] = None
    messages: Optional[list[BaseMessage]] = Field(None, min_length=1)
    model_id: Optional[str] = None
    moderations: Optional[ModerationParameters] = None
    parameters: Optional[TextGenerationParameters] = None
    parent_id: Optional[str] = None
    prompt_id: Optional[str] = None
    prompt_template_id: Optional[str] = None
    trim_method: Optional[TrimMethod] = None
    use_conversation_parameters: Optional[bool] = None


class TextChatStreamCreateResponse(ApiBaseModel):
    conversation_id: str
    created_at: Optional[AwareDatetime] = None
    id: Optional[str] = None
    input_parameters: Optional[dict[str, Any]] = None
    model_id: Optional[str] = None
    moderations: Optional[TextCreateResponseModeration] = None
    results: Optional[list[TextChatGenerationStreamResult]] = None

    @computed_field
    @deprecated.deprecated(reason="'moderation' property is deprecated, use 'moderations' instead!")
    def moderation(self) -> Optional[TextCreateResponseModeration]:
        return self.moderations


class _TextClassificationCreateParametersQuery(ApiBaseModel):
    version: Literal["2023-11-22"] = "2023-11-22"


class _TextClassificationCreateRequest(ApiBaseModel):
    data: list[TextClassificationCreateData] = Field(..., min_length=1)
    input: str
    model_id: str


class TextClassificationCreateResponse(ApiBaseModel):
    result: TextClassificationResult


class _TextEmbeddingCreateParametersQuery(ApiBaseModel):
    version: Literal["2023-11-22"] = "2023-11-22"


class _TextEmbeddingCreateRequest(ApiBaseModel):
    input: Union[str, Input]
    model_id: str
    parameters: Optional[TextEmbeddingParameters] = None


class TextEmbeddingCreateResponse(ApiBaseModel):
    results: list[list[float]]


class _TextEmbeddingLimitRetrieveParametersQuery(ApiBaseModel):
    version: Literal["2023-11-22"] = "2023-11-22"


class TextEmbeddingLimitRetrieveResponse(ApiBaseModel):
    result: TextEmbeddingLimit


class _TextExtractionLimitRetrieveParametersQuery(ApiBaseModel):
    version: Literal["2023-11-22"] = "2023-11-22"


class _TextGenerationComparisonCreateParametersQuery(ApiBaseModel):
    version: Literal["2024-03-19"] = "2024-03-19"


class _TextGenerationComparisonCreateRequest(ApiBaseModel):
    compare_parameters: TextGenerationComparisonParameters
    name: Optional[str] = None
    request: TextGenerationComparisonCreateRequestRequest


class TextGenerationComparisonCreateResponse(ApiBaseModel):
    results: list[TextGenerationComparisonCreateResults]


class _TextGenerationCreateParametersQuery(ApiBaseModel):
    version: Literal["2024-03-19"] = "2024-03-19"


class _TextGenerationCreateRequest(ApiBaseModel):
    data: Optional[PromptTemplateData] = None
    input: Optional[str] = Field(None, examples=["How are you"], title="Input string")
    """
    The input is the prompt to generate completions, passed as a string. Note: The method tokenizes the input internally. It is recommended not to leave any trailing spaces.
    """
    model_id: Optional[str] = Field(None, title="Model ID")
    """
    The ID of the model or tune to be used for this request.
    """
    moderations: Optional[ModerationParameters] = None
    parameters: Optional[TextGenerationParameters] = None
    prompt_id: Optional[str] = Field(None, min_length=1, title="Saved prompt Id")


class TextGenerationCreateResponse(ApiBaseModel):
    created_at: AwareDatetime
    id: str
    input_parameters: Optional[dict[str, Any]] = None
    model_id: str
    results: list[TextGenerationResult]


class _TextGenerationIdFeedbackCreateParametersQuery(ApiBaseModel):
    version: Literal["2024-02-20"] = "2024-02-20"


class _TextGenerationIdFeedbackCreateRequest(ApiBaseModel):
    categories: Optional[list[TextGenerationFeedbackCategory]] = Field(None, min_length=1)
    comment: Optional[str] = None
    contact_consent: Optional[bool] = False
    vote: Optional[TextGenerationFeedbackVote] = None


class TextGenerationIdFeedbackCreateResponse(ApiBaseModel):
    result: TextGenerationFeedbackResult


class _TextGenerationIdFeedbackRetrieveParametersQuery(ApiBaseModel):
    version: Literal["2023-11-22"] = "2023-11-22"


class TextGenerationIdFeedbackRetrieveResponse(ApiBaseModel):
    result: TextGenerationFeedbackResult


class _TextGenerationIdFeedbackUpdateParametersQuery(ApiBaseModel):
    version: Literal["2024-02-20"] = "2024-02-20"


class _TextGenerationIdFeedbackUpdateRequest(ApiBaseModel):
    categories: Optional[list[TextGenerationFeedbackCategory]] = Field(None, min_length=1)
    comment: Optional[str] = None
    contact_consent: Optional[bool] = False
    vote: Optional[TextGenerationFeedbackVote] = None


class TextGenerationIdFeedbackUpdateResponse(ApiBaseModel):
    result: TextGenerationFeedbackResult


class _TextGenerationLimitRetrieveParametersQuery(ApiBaseModel):
    version: Literal["2023-11-22"] = "2023-11-22"


class TextGenerationLimitRetrieveResponse(ApiBaseModel):
    result: TextGenerationLimit


class _TextGenerationOutputCreateParametersQuery(ApiBaseModel):
    version: Literal["2024-03-19"] = "2024-03-19"


class _TextGenerationOutputCreateRequest(ApiBaseModel):
    data: Optional[PromptTemplateData] = None
    input: Optional[str] = None
    model_id: Optional[str] = None
    moderations: Optional[ModerationParameters] = None
    parameters: Optional[TextGenerationParameters] = None
    prompt_id: Optional[str] = None
    use_default: Optional[bool] = None


class TextGenerationOutputCreateResponse(ApiBaseModel):
    results: list[str]


class _TextGenerationStreamCreateParametersQuery(ApiBaseModel):
    version: Literal["2024-03-19"] = "2024-03-19"


class _TextGenerationStreamCreateRequest(ApiBaseModel):
    data: Optional[PromptTemplateData] = None
    input: Optional[str] = Field(None, examples=["How are you"], title="Input string")
    """
    The input is the prompt to generate completions, passed as a string. Note: The method tokenizes the input internally. It is recommended not to leave any trailing spaces.
    """
    model_id: Optional[str] = Field(None, title="Model ID")
    """
    The ID of the model or tune to be used for this request.
    """
    moderations: Optional[ModerationParameters] = None
    parameters: Optional[TextGenerationParameters] = None
    prompt_id: Optional[str] = Field(None, min_length=1, title="Saved prompt Id")


class TextGenerationStreamCreateResponse(ApiBaseModel):
    created_at: Optional[AwareDatetime] = None
    id: Optional[str] = None
    input_parameters: Optional[dict[str, Any]] = None
    model_id: str
    moderations: Optional[TextCreateResponseModeration] = None
    results: Optional[list[TextGenerationStreamResult]] = None

    @computed_field
    @deprecated.deprecated(reason="'moderation' property is deprecated, use 'moderations' instead!")
    def moderation(self) -> Optional[TextCreateResponseModeration]:
        return self.moderations


class _TextModerationCreateParametersQuery(ApiBaseModel):
    version: Literal["2024-03-19"] = "2024-03-19"


class _TextModerationCreateRequest(ApiBaseModel):
    hap: Optional[HAPOptions] = None
    input: str = Field(..., max_length=20480)
    social_bias: Optional[SocialBiasOptions] = None


class TextModerationCreateResponse(ApiBaseModel):
    results: list[TextCreateResponseModeration]


class _TextRerankCreateParametersQuery(ApiBaseModel):
    version: Literal["2023-11-22"] = "2023-11-22"


class _TextRerankCreateRequest(ApiBaseModel):
    documents: list[str] = Field(..., min_length=1)
    model_id: str
    parameters: Optional[TextRerankParameters] = None
    query: str


class TextRerankCreateResponse(ApiBaseModel):
    result: _TextRerankCreateResult


class _TextSentenceSimilarityCreateParametersQuery(ApiBaseModel):
    version: Literal["2023-11-22"] = "2023-11-22"


class _TextSentenceSimilarityCreateRequest(ApiBaseModel):
    model_id: str
    parameters: Optional[TextSentenceSimilarityParameters] = None
    sentences: list[str] = Field(..., min_length=1)
    source_sentence: str


class TextSentenceSimilarityCreateResponse(ApiBaseModel):
    results: list[TextSentenceSimilarityCreateResult]


class _TextTokenizationCreateParametersQuery(ApiBaseModel):
    version: Literal["2024-01-10"] = "2024-01-10"


class _TextTokenizationCreateRequest(ApiBaseModel):
    data: Optional[PromptTemplateData] = None
    input: Optional[Union[str, list[str]]] = None
    model_id: Optional[str] = None
    parameters: Optional[TextTokenizationParameters] = None
    prompt_id: Optional[str] = None


class TextTokenizationCreateResponse(ApiBaseModel):
    created_at: str
    model_id: str
    results: list[TextTokenizationCreateResults]


class _TuneCreateParametersQuery(ApiBaseModel):
    version: Literal["2023-11-22"] = "2023-11-22"


class _TuneCreateRequest(ApiBaseModel):
    evaluation_file_ids: Optional[list[str]] = None
    model_id: str
    name: str
    parameters: Optional[TuneParameters] = None
    task_id: str
    training_file_ids: list[str]
    tuning_type: str
    validation_file_ids: Optional[list[str]] = None


class TuneCreateResponse(ApiBaseModel):
    result: TuneResult


class _TuneFromFileCreateParametersQuery(ApiBaseModel):
    version: Literal["2023-11-22"] = "2023-11-22"


class _TuneFromFileCreateRequest(ApiBaseModel):
    file_id: str
    name: str


class TuneFromFileCreateResponse(ApiBaseModel):
    result: TuneResult


class _TuneIdContentTypeRetrieveParametersQuery(ApiBaseModel):
    version: Literal["2023-12-15"] = "2023-12-15"


class _TuneIdDeleteParametersQuery(ApiBaseModel):
    version: Literal["2023-11-22"] = "2023-11-22"


class _TuneIdPatchParametersQuery(ApiBaseModel):
    version: Literal["2023-11-22"] = "2023-11-22"


class _TuneIdPatchRequest(ApiBaseModel):
    name: Optional[str] = None
    preferred: Optional[bool] = None


class TuneIdPatchResponse(ApiBaseModel):
    result: TuneResult


class _TuneIdRetrieveParametersQuery(ApiBaseModel):
    version: Literal["2023-11-22"] = "2023-11-22"


class TuneIdRetrieveResponse(ApiBaseModel):
    result: TuneResult


class _TuneRetrieveParametersQuery(ApiBaseModel):
    limit: Optional[int] = Field(100, ge=1, le=100)
    offset: Optional[int] = Field(0, ge=0)
    status: Optional[TuneStatus] = None
    search: Optional[str] = None
    sort_by: Optional[TuneListSortBy] = None
    direction: Optional[SortDirection] = None
    version: Literal["2023-11-22"] = "2023-11-22"


class TuneRetrieveResponse(ApiBaseModel):
    results: list[TuneResult]
    total_count: int


class _TuningTypeRetrieveParametersQuery(ApiBaseModel):
    version: Literal["2024-01-30"] = "2024-01-30"


class TuningTypeRetrieveResponse(ApiBaseModel):
    results: list[TuningTypeRetrieveResults]


class _UserCreateParametersQuery(ApiBaseModel):
    version: Literal["2023-11-22"] = "2023-11-22"


class _UserCreateRequest(ApiBaseModel):
    first_name: Optional[str] = None
    last_name: Optional[str] = None


class UserCreateResponse(ApiBaseModel):
    result: UserCreateResult


class _UserDeleteParametersQuery(ApiBaseModel):
    version: Literal["2023-11-22"] = "2023-11-22"


class _UserPatchParametersQuery(ApiBaseModel):
    version: Literal["2023-11-22"] = "2023-11-22"


class _UserPatchRequest(ApiBaseModel):
    data_usage_consent: Optional[bool] = None
    tou_accepted: Optional[bool] = None


class UserPatchResponse(ApiBaseModel):
    result: UserResult


class _UserRetrieveParametersQuery(ApiBaseModel):
    version: Literal["2023-11-22"] = "2023-11-22"


class UserRetrieveResponse(ApiBaseModel):
    result: UserResult


class _BetaTimeSerieForecastingCreateRequestColumns(ApiBaseModel):
    conditional: Optional[list[str]] = None
    control: Optional[list[str]] = None
    id: Optional[list[str]] = None
    observable: Optional[list[str]] = None
    static_categorical: Optional[list[str]] = None
    target: Optional[list[str]] = None
    timestamp: str


class _BetaTimeSerieForecastingCreateResult(ApiBaseModel):
    predictions: str


class _BetaTimeSerieLimitRetrieveResult(ApiBaseModel):
    concurrency: _BetaTimeSerieLimitRetrieveResultConcurrency


class _BetaTimeSerieLimitRetrieveResultConcurrency(ApiBaseModel):
    limit: int
    remaining: int


class _TextRerankCreateResult(ApiBaseModel):
    query: Optional[str] = None
    results: list[TextRerankResult]


class PromptListSortBy(str, Enum):
    TYPE = "type"
    MODEL_TASK = "model_task"
    UPDATED_AT = "updated_at"
    CREATED_AT = "created_at"
    NAME = "name"
    ID = "id"
    MODEL = "model"
    USAGE_COUNT = "usage_count"


class PromptListSource(str, Enum):
    USER = "user"
    EXAMPLE = "example"
    COMMUNITY = "community"


class PromptModerationParameters(ModerationParameters):
    hap: Optional[ModerationHAP] = None
    implicit_hate: Optional[ModerationImplicitHate] = None
    social_bias: Optional[ModerationSocialBias] = None
    stigma: Optional[ModerationStigma] = None


class PromptResult(ApiBaseModel):
    author: Optional[PromptResultAuthor] = None
    created_at: AwareDatetime
    data: Optional[dict[str, Any]] = None
    description: Optional[str] = None
    folder_id: Optional[str] = None
    id: str
    input: Optional[str] = None
    messages: Optional[list[BaseMessage]] = None
    metadata: Optional[dict[str, Any]] = None
    model_id: Optional[str] = None
    moderations: Optional[PromptModerationParameters] = None
    name: str
    output: Optional[str] = None
    parameters: Optional[TextGenerationParameters] = None
    prompt_id: Optional[str] = None
    public: Optional[bool] = None
    tags: Optional[list[PromptTag]] = None
    task: Optional[PromptResultTask] = None
    type: PromptType
    updated_at: Optional[AwareDatetime] = None
    usage_count: int


class PromptResultAuthor(ApiBaseModel):
    first_name: Optional[str] = None
    id: Optional[int] = None
    last_name: Optional[str] = None


class PromptResultTask(ApiBaseModel):
    icon: Optional[str] = None
    id: Optional[str] = None
    name: Optional[str] = None


class PromptTag(ApiBaseModel):
    id: str
    name: str
    type: PromptTagType


class PromptTagType(str, Enum):
    LANGUAGE = "language"
    INDUSTRY = "industry"
    MODEL_TYPE = "model_type"


class PromptTemplateData(ApiBaseModel):
    example_file_ids: Optional[list[str]] = Field(None, max_length=5, min_length=0)


class PromptType(str, Enum):
    PRIVATE = "private"
    PUBLIC = "public"
    COMMUNITY = "community"
    EXAMPLE = "example"


class RequestApiVersion(str, Enum):
    V0 = "v0"
    V1 = "v1"
    V2 = "v2"


class RequestChatConversationIdRetrieveResults(ApiBaseModel):
    created_at: AwareDatetime
    duration: int
    id: str
    parent_id: Optional[str] = None
    request: Optional[RequestChatConversationIdRetrieveResultsRequest] = None
    response: Optional[RequestChatConversationIdRetrieveResultsResponse] = None
    status: RequestStatus
    version: Optional[RequestResultVersion] = None


class RequestChatConversationIdRetrieveResultsRequest(ApiBaseModel):
    pass


class RequestChatConversationIdRetrieveResultsResponse(ApiBaseModel):
    pass


class RequestEndpoint(str, Enum):
    GENERATE = "generate"
    COMPARE = "compare"
    CHAT = "chat"


class RequestFeedbackCategory(str, Enum):
    INACCURATE = "inaccurate"
    NOT_RELEVANT = "not_relevant"
    OFFENSIVE_HARMFUL = "offensive_harmful"
    KNOWLEDGE_GAP = "knowledge_gap"
    OTHER_CONTENT = "other_content"
    TOO_LONG = "too_long"
    TOO_SHORT = "too_short"
    WRONG_TONE = "wrong_tone"
    WRONG_FORMAT = "wrong_format"
    OTHER_STYLE = "other_style"
    CORRECT_CONTENT = "correct_content"
    CORRECT_STYLE = "correct_style"


class RequestFeedbackResult(ApiBaseModel):
    api_request: str
    categories: list[str]
    comment: Optional[str] = None
    contact_consent: bool
    created_at: AwareDatetime
    id: int
    updated_at: AwareDatetime
    vote: Optional[RequestFeedbackVote] = None


class RequestFeedbackVote(str, Enum):
    UP = "up"
    DOWN = "down"


class RequestOrigin(str, Enum):
    API = "api"
    UI = "ui"


class RequestResultVersion(ApiBaseModel):
    api: Optional[str] = None
    date_: Optional[date] = Field(None, alias="date")


class RequestRetrieveResults(ApiBaseModel):
    created_at: AwareDatetime
    duration: int
    id: str
    request: Optional[dict[str, Any]] = None
    response: Optional[dict[str, Any]] = None
    status: RequestStatus
    version: Optional[RequestResultVersion] = None


class RequestStatus(str, Enum):
    SUCCESS = "success"
    ERROR = "error"


class SocialBiasOptions(ApiBaseModel):
    send_tokens: Optional[bool] = False
    threshold: Optional[float] = Field(0.75, gt=0.0, lt=1.0)


class SortDirection(str, Enum):
    ASC = "asc"
    DESC = "desc"


class StopReason(str, Enum):
    NOT_FINISHED = "not_finished"
    MAX_TOKENS = "max_tokens"
    EOS_TOKEN = "eos_token"
    CANCELLED = "cancelled"
    TIME_LIMIT = "time_limit"
    STOP_SEQUENCE = "stop_sequence"
    TOKEN_LIMIT = "token_limit"
    ERROR = "error"


class StorageProviderLocation(str, Enum):
    US_SOUTH = "us-south"
    US_EAST = "us-east"


class SystemPrompt(ApiBaseModel):
    author: Optional[SystemPromptAuthor] = None
    content: str
    created_at: AwareDatetime
    id: int
    name: str
    type: SystemPromptType


class SystemPromptAuthor(ApiBaseModel):
    first_name: Optional[str] = None
    id: int
    last_name: Optional[str] = None


class SystemPromptType(str, Enum):
    PRIVATE = "private"
    SYSTEM = "system"


class Tag(ApiBaseModel):
    id: str
    name: str
    type: TagType


class TagType(str, Enum):
    LANGUAGE = "language"
    INDUSTRY = "industry"
    MODEL_TYPE = "model_type"


class Tasks(ApiBaseModel):
    categorization: bool
    csv_example: Optional[str] = None
    file_format_id: Optional[int] = None
    id: str
    json_example: Optional[str] = None
    jsonl_example: Optional[str] = None
    name: str
    tune: bool
    verbalizer: Optional[str] = None


class TextChatGenerationStreamResult(ApiBaseModel):
    generated_text: str
    generated_token_count: int
    generated_tokens: Optional[list[BaseTokens]] = None
    input_text: Optional[str] = None
    input_token_count: Optional[int] = None
    input_tokens: Optional[list[BaseTokens]] = None
    seed: Optional[float] = None
    stop_reason: StopReason
    stop_sequence: Optional[str] = None


class TextClassificationCreateData(ApiBaseModel):
    labels: list[str]
    text: str


class TextClassificationResult(ApiBaseModel):
    classification_type: TextClassificationType
    log_likelihood: dict[str, float]
    model_input: str
    model_output: str
    predictions: list[str]


class TextClassificationType(str, Enum):
    MULTI_CLASS = "multi_class"
    MULTI_LABEL = "multi_label"
    BINARY = "binary"


class TextCreateResponseModeration(ApiBaseModel):
    hap: Optional[list[TextModeration]] = None
    social_bias: Optional[list[TextModeration]] = None

    @computed_field
    @deprecated.deprecated(reason="'stigma' property is deprecated, use 'social_bias' instead!")
    def stigma(self) -> Optional[list[TextModeration]]:
        return None

    @computed_field
    @deprecated.deprecated(reason="'implicit_hate' property is deprecated, use 'social_bias' instead!")
    def implicit_hate(self) -> Optional[list[TextModeration]]:
        return None


class TextEmbeddingLimit(ApiBaseModel):
    concurrency: ConcurrencyLimit


class TextEmbeddingParameters(ApiBaseModel):
    truncate_input_tokens: Optional[bool] = None


class TextGenerationComparisonCreateRequestRequest(ApiBaseModel):
    data: Optional[PromptTemplateData] = None
    input: str
    model_id: Optional[str] = None
    moderations: Optional[ModerationParameters] = None
    parameters: Optional[TextGenerationParameters] = None
    prompt_id: Optional[str] = None
    use_default: Optional[bool] = None


class TextGenerationComparisonCreateResults(ApiBaseModel):
    error: Optional[Any] = None
    parameters: TextGenerationComparisonCreateResultsParameters
    result: Optional[TextGenerationComparisonCreateResultsResult] = None


class TextGenerationComparisonCreateResultsParameters(ApiBaseModel):
    length_penalty: Optional[dict[str, Any]] = None
    model_id: Optional[str] = None
    repetition_penalty: Optional[float] = None
    temperature: Optional[float] = None
    top_k: Optional[int] = None
    top_p: Optional[float] = None
    typical_p: Optional[float] = None


class TextGenerationComparisonCreateResultsResult(ApiBaseModel):
    created_at: AwareDatetime
    id: str
    input_parameters: Optional[dict[str, Any]] = None
    model_id: str
    results: list[TextGenerationResult]


class TextGenerationComparisonParameters(ApiBaseModel):
    length_penalty: Optional[list[dict[str, Any]]] = Field(None, max_length=10, min_length=1)
    model_id: Optional[list[str]] = Field(None, max_length=10, min_length=1)
    repetition_penalty: Optional[list[float]] = Field(None, max_length=10, min_length=1)
    temperature: Optional[list[float]] = Field(None, max_length=10, min_length=1)
    top_k: Optional[list[int]] = Field(None, max_length=10, min_length=1)
    top_p: Optional[list[float]] = Field(None, max_length=10, min_length=1)
    typical_p: Optional[list[float]] = Field(None, max_length=10, min_length=1)


class TextGenerationFeedbackCategory(str, Enum):
    INACCURATE = "inaccurate"
    NOT_RELEVANT = "not_relevant"
    OFFENSIVE_HARMFUL = "offensive_harmful"
    KNOWLEDGE_GAP = "knowledge_gap"
    OTHER_CONTENT = "other_content"
    TOO_LONG = "too_long"
    TOO_SHORT = "too_short"
    WRONG_TONE = "wrong_tone"
    WRONG_FORMAT = "wrong_format"
    OTHER_STYLE = "other_style"
    CORRECT_CONTENT = "correct_content"
    CORRECT_STYLE = "correct_style"


class TextGenerationFeedbackResult(ApiBaseModel):
    api_request: str
    categories: list[str]
    comment: Optional[str] = None
    contact_consent: bool
    created_at: AwareDatetime
    id: int
    updated_at: AwareDatetime
    vote: Optional[TextGenerationFeedbackVote] = None


class TextGenerationFeedbackVote(str, Enum):
    UP = "up"
    DOWN = "down"


class TextGenerationLimit(ApiBaseModel):
    concurrency: ConcurrencyLimit


class TextGenerationParameters(ApiBaseModel):
    beam_width: Optional[int] = Field(None, ge=0, le=3, title="Beam width")
    """
    At each step, or token, the algorithm keeps track of the n (off=1, 2, or 3) most probable sequences (beams) and selects the one with the highest probability. This continues until the stop sequence is met.
    """
    decoding_method: Optional[DecodingMethod] = None
    include_stop_sequence: Optional[bool] = None
    length_penalty: Optional[LengthPenalty] = None
    max_new_tokens: Optional[int] = Field(None, ge=0, title="Max new tokens")
    """
    Define the maximum number of tokens to generate.
    """
    min_new_tokens: Optional[int] = Field(None, ge=0, title="Min new tokens")
    """
    If stop sequences are given, they are ignored until minimum tokens are generated.
    """
    random_seed: Optional[int] = Field(None, ge=1, le=4294967295, title="Random seed")
    """
    Controls the random sampling of the generated tokens when sampling is enabled. Setting the random seed to a the same number for each generation ensures experimental repeatability.
    """
    repetition_penalty: Optional[float] = Field(None, ge=1.0, le=2.0, multiple_of=0.01, title="Repetition penalty")
    """
    The parameter for repetition penalty. 1.00 means no penalty.
    """
    return_options: Optional[TextGenerationReturnOptions] = None
    stop_sequences: Optional[list[str]] = Field(
        None, examples=['[" and "]'], max_length=6, min_length=1, title="Stop sequences"
    )
    """
    Stop sequences are one or more strings which will cause the text generation to stop if/when they are produced as part of the output. Stop sequences encountered prior to the minimum number of tokens being generated will be ignored.
    """
    temperature: Optional[float] = Field(None, ge=0.0, le=2.0, multiple_of=0.01, title="Temperature")
    """
    Control the creativity of generated text. Higher values will lead to more randomly generated outputs.
    """
    time_limit: Optional[int] = Field(None, title="Time limit")
    """
    Time limit in milliseconds - if not completed within this time, generation will stop. The text generated so far will be returned along with the `TIME_LIMIT` stop reason.
    """
    top_k: Optional[int] = Field(None, ge=1, le=100, title="Top K")
    """
    Set the number of highest probability vocabulary tokens to keep for top-k-filtering. Lower values make it less likely the model will go off topic.
    """
    top_p: Optional[float] = Field(None, ge=0.0, le=1.0, multiple_of=0.01, title="Top P (nucleus sampling)")
    """
    If < 1.0, only the smallest set of most probable tokens with probabilities that add up to `top_p` or higher are used.
    """
    truncate_input_tokens: Optional[int] = Field(None, ge=0, title="Truncate input tokens")
    """
    Truncate to this many input tokens. Can be used to avoid requests failing due to input being longer than configured limits. Zero means don't truncate.
    """
    typical_p: Optional[float] = Field(None, ge=0.01, le=1.0, multiple_of=0.01, title="Typical P")
    """
    Local typicality measures how similar the conditional probability of predicting a target token next is to the expected conditional probability of predicting a random token next, given the partial text already generated. If set to float < 1, the smallest set of the most locally typical tokens with probabilities that add up to typical_p or higher are kept for generation. 1.00 means a neutral value.
    """


class TextGenerationResult(ApiBaseModel):
    generated_text: str
    generated_token_count: int
    generated_tokens: Optional[list[BaseTokens]] = None
    input_text: Optional[str] = None
    input_token_count: Optional[int] = None
    input_tokens: Optional[list[BaseTokens]] = None
    moderations: Optional[TextCreateResponseModeration] = None
    seed: Optional[float] = None
    stop_reason: StopReason
    stop_sequence: Optional[str] = None

    @computed_field
    @deprecated.deprecated(reason="'moderation' property is deprecated, use 'moderations' instead!")
    def moderation(self) -> Optional[TextCreateResponseModeration]:
        return self.moderations


class TextGenerationReturnOptions(ApiBaseModel):
    generated_tokens: Optional[bool] = Field(False, title="Generated Tokens")
    """
    Include list of individual generated tokens
    """
    input_parameters: Optional[bool] = None
    input_text: Optional[bool] = Field(False, title="Input text")
    """
    Include input text
    """
    input_tokens: Optional[bool] = Field(False, title="Input Tokens")
    """
    Include list of input tokens
    """
    token_logprobs: Optional[bool] = Field(False, title="Token logprobs")
    """
    Include logprob for each returned token
    """
    token_ranks: Optional[bool] = Field(False, title="Token ranks")
    """
    Include rank of each returned token
    """
    top_n_tokens: Optional[int] = Field(None, ge=0, le=5, title="Top N tokens")
    """
    Include top n candidate tokens at the position of each returned token
    """


class TextGenerationStreamResult(ApiBaseModel):
    generated_text: str
    generated_token_count: int
    generated_tokens: Optional[list[BaseTokens]] = None
    input_text: Optional[str] = None
    input_token_count: Optional[int] = None
    input_tokens: Optional[list[BaseTokens]] = None
    seed: Optional[float] = None
    stop_reason: StopReason
    stop_sequence: Optional[str] = None


class TextModeration(ApiBaseModel):
    flagged: bool
    position: ModerationPosition
    score: float
    success: bool
    tokens: Optional[list[ModerationTokens]] = None


class TextRerankParameters(ApiBaseModel):
    return_options: Optional[TextRerankReturnOptions] = None
    truncate_input_tokens: Optional[bool] = None


class TextRerankResult(ApiBaseModel):
    score: float


class TextRerankReturnOptions(ApiBaseModel):
    documents: Optional[bool] = None
    query: Optional[bool] = None
    top_n: Optional[float] = Field(None, ge=1.0)


class TextSentenceSimilarityCreateResult(ApiBaseModel):
    score: float


class TextSentenceSimilarityParameters(ApiBaseModel):
    truncate_input_tokens: Optional[bool] = None


class TextTokenizationCreateResults(ApiBaseModel):
    input_text: Optional[str] = None
    token_count: int
    tokens: Optional[list[str]] = None


class TextTokenizationParameters(ApiBaseModel):
    return_options: Optional[TextTokenizationReturnOptions] = None


class TextTokenizationReturnOptions(ApiBaseModel):
    input_text: Optional[bool] = None
    tokens: Optional[bool] = None


class TooManyRequestsResponse(BaseErrorResponse):
    extensions: Extensions3
    status_code: Literal[429] = 429


class TrimMethod(str, Enum):
    FLOATING_WINDOW = "floating_window"
    NONE = "none"


class TuneAssetType(str, Enum):
    VECTORS = "vectors"
    LOGS = "logs"
    EXPORT = "export"


class TuneListSortBy(str, Enum):
    STATUS = "status"
    CREATED_AT = "created_at"
    NAME = "name"
    ID = "id"
    MODEL = "model"


class TuneParameters(ApiBaseModel):
    accumulate_steps: Optional[int] = None
    batch_size: Optional[int] = None
    learning_rate: Optional[float] = None
    max_input_tokens: Optional[int] = None
    max_output_tokens: Optional[int] = None
    num_epochs: Optional[int] = None
    num_virtual_tokens: Optional[int] = None
    verbalizer: Optional[str] = None


class TuneResult(ApiBaseModel):
    created_at: AwareDatetime
    datapoints: Optional[TuneResultDatapoints] = None
    evaluation_files: Optional[list[TuneResultFiles]] = None
    finished_at: Optional[AwareDatetime] = None
    id: str
    model_id: str
    model_name: str
    name: str
    parameters: Optional[dict[str, Any]] = None
    preferred: bool
    started_at: Optional[AwareDatetime] = None
    status: TuneStatus
    status_message: Optional[str] = None
    task_id: str
    task_name: str
    training_files: Optional[list[TuneResultFiles]] = None
    tuning_type: str
    validation_files: Optional[list[TuneResultFiles]] = None
    vectors: Optional[str] = None


class TuneResultDatapointLoss(ApiBaseModel):
    epoch: int
    step: Optional[int] = None
    value: float


class TuneResultDatapoints(ApiBaseModel):
    loss: list[TunesResultDatapointLoss]


class TuneResultFiles(ApiBaseModel):
    created_at: Optional[AwareDatetime] = None
    file_name: str
    id: str


class TuneStatus(str, Enum):
    INITIALIZING = "initializing"
    NOT_STARTED = "not_started"
    PENDING = "pending"
    HALTED = "halted"
    RUNNING = "running"
    QUEUED = "queued"
    COMPLETED = "completed"
    FAILED = "failed"


class TunesResultDatapointLoss(ApiBaseModel):
    data: TuneResultDatapointLoss
    timestamp: AwareDatetime


class TuningTypeRetrieveResults(ApiBaseModel):
    id: Optional[str] = None
    model_ids: Optional[list[str]] = None
    name: Optional[str] = None
    schema_: Optional[dict[str, Any]] = Field(None, alias="schema")
    """
    JSON Schema
    """


class UnauthorizedResponse(BaseErrorResponse):
    extensions: Extensions4
    status_code: Literal[401] = 401


class UnavailableResponse(BaseErrorResponse):
    extensions: Extensions5
    status_code: Literal[503] = 503


class UserApiKey(ApiBaseModel):
    created_at: str
    generated_at: str
    last_used_at: Optional[str] = None
    value: str


class UserCreateResult(ApiBaseModel):
    api_key: UserApiKey
    data_usage_consent: bool
    email: str
    first_name: Optional[str] = None
    generate_default: Optional[UserGenerationDefault] = None
    id: int
    last_name: Optional[str] = None
    tou_accepted: bool
    tou_accepted_at: Optional[str] = None
    user_id: str


class UserGenerationDefault(ApiBaseModel):
    model_id: Optional[str] = None
    parameters: Optional[TextGenerationParameters] = None


class UserResult(ApiBaseModel):
    data_usage_consent: bool
    email: str
    first_name: Optional[str] = None
    generate_default: Optional[UserGenerationDefault] = None
    id: int
    last_name: Optional[str] = None
    tou_accepted: bool
    tou_accepted_at: Optional[str] = None


class BadRequestResponse(BaseErrorResponse):
    extensions: Extensions
    status_code: Literal[400] = 400


__all__ = [
    "ApiKeyRegenerateCreateResponse",
    "ApiKeyResult",
    "ApiKeyRetrieveResponse",
    "BadRequestResponse",
    "BaseErrorExtension",
    "BaseErrorResponse",
    "BaseMessage",
    "BaseTokens",
    "BetaTimeSerieForecastingCreateResponse",
    "BetaTimeSerieLimitRetrieveResponse",
    "ChatRole",
    "ConcurrencyLimit",
    "DecodingMethod",
    "Extensions",
    "Extensions1",
    "Extensions2",
    "Extensions3",
    "Extensions4",
    "Extensions5",
    "FileCreateResponse",
    "FileDescendant",
    "FileFormat",
    "FileIdPatchResponse",
    "FileIdRetrieveResponse",
    "FileListSortBy",
    "FilePurpose",
    "FileResult",
    "FileRetrieveResponse",
    "FolderCreateResponse",
    "FolderIdPatchResponse",
    "FolderIdRetrieveResponse",
    "FolderIdUpdateResponse",
    "FolderResult",
    "FolderRetrieveResponse",
    "GeneratedToken",
    "HAPOptions",
    "Input",
    "InternalServerErrorResponse",
    "LengthPenalty",
    "MessageFile",
    "ModelFacet",
    "ModelFacetType",
    "ModelFamily",
    "ModelIdRetrieveResponse",
    "ModelIdRetrieveResult",
    "ModelRetrieveResponse",
    "ModelRetrieveResults",
    "ModelTokenLimits",
    "ModelType",
    "ModerationHAP",
    "ModerationHAPInput",
    "ModerationHAPOutput",
    "ModerationImplicitHate",
    "ModerationImplicitHateInput",
    "ModerationImplicitHateOutput",
    "ModerationParameters",
    "ModerationPosition",
    "ModerationSocialBias",
    "ModerationSocialBiasInput",
    "ModerationSocialBiasOutput",
    "ModerationStigma",
    "ModerationStigmaInput",
    "ModerationStigmaOutput",
    "ModerationTokens",
    "NotFoundResponse",
    "PromptCreateResponse",
    "PromptIdPatchResponse",
    "PromptIdRetrieveResponse",
    "PromptIdUpdateResponse",
    "PromptListSortBy",
    "PromptListSource",
    "PromptModerationParameters",
    "PromptResult",
    "PromptResultAuthor",
    "PromptResultTask",
    "PromptRetrieveResponse",
    "PromptTag",
    "PromptTagType",
    "PromptTemplateData",
    "PromptType",
    "RequestApiVersion",
    "RequestChatConversationIdRetrieveResponse",
    "RequestChatConversationIdRetrieveResults",
    "RequestChatConversationIdRetrieveResultsRequest",
    "RequestChatConversationIdRetrieveResultsResponse",
    "RequestEndpoint",
    "RequestFeedbackCategory",
    "RequestFeedbackResult",
    "RequestFeedbackVote",
    "RequestIdFeedbackCreateResponse",
    "RequestIdFeedbackRetrieveResponse",
    "RequestIdFeedbackUpdateResponse",
    "RequestOrigin",
    "RequestResultVersion",
    "RequestRetrieveResponse",
    "RequestRetrieveResults",
    "RequestStatus",
    "SocialBiasOptions",
    "SortDirection",
    "StopReason",
    "StorageProviderLocation",
    "SystemPrompt",
    "SystemPromptAuthor",
    "SystemPromptCreateResponse",
    "SystemPromptIdRetrieveResponse",
    "SystemPromptIdUpdateResponse",
    "SystemPromptRetrieveResponse",
    "SystemPromptType",
    "Tag",
    "TagRetrieveResponse",
    "TagType",
    "TaskRetrieveResponse",
    "Tasks",
    "TextChatCreateResponse",
    "TextChatGenerationStreamResult",
    "TextChatOutputCreateResponse",
    "TextChatStreamCreateResponse",
    "TextClassificationCreateData",
    "TextClassificationCreateResponse",
    "TextClassificationResult",
    "TextClassificationType",
    "TextCreateResponseModeration",
    "TextEmbeddingCreateResponse",
    "TextEmbeddingLimit",
    "TextEmbeddingLimitRetrieveResponse",
    "TextEmbeddingParameters",
    "TextGenerationComparisonCreateRequestRequest",
    "TextGenerationComparisonCreateResponse",
    "TextGenerationComparisonCreateResults",
    "TextGenerationComparisonCreateResultsParameters",
    "TextGenerationComparisonCreateResultsResult",
    "TextGenerationComparisonParameters",
    "TextGenerationCreateResponse",
    "TextGenerationFeedbackCategory",
    "TextGenerationFeedbackResult",
    "TextGenerationFeedbackVote",
    "TextGenerationIdFeedbackCreateResponse",
    "TextGenerationIdFeedbackRetrieveResponse",
    "TextGenerationIdFeedbackUpdateResponse",
    "TextGenerationLimit",
    "TextGenerationLimitRetrieveResponse",
    "TextGenerationOutputCreateResponse",
    "TextGenerationParameters",
    "TextGenerationResult",
    "TextGenerationReturnOptions",
    "TextGenerationStreamCreateResponse",
    "TextGenerationStreamResult",
    "TextModeration",
    "TextModerationCreateResponse",
    "TextRerankCreateResponse",
    "TextRerankParameters",
    "TextRerankResult",
    "TextRerankReturnOptions",
    "TextSentenceSimilarityCreateResponse",
    "TextSentenceSimilarityCreateResult",
    "TextSentenceSimilarityParameters",
    "TextTokenizationCreateResponse",
    "TextTokenizationCreateResults",
    "TextTokenizationParameters",
    "TextTokenizationReturnOptions",
    "TooManyRequestsResponse",
    "TrimMethod",
    "TuneAssetType",
    "TuneCreateResponse",
    "TuneFromFileCreateResponse",
    "TuneIdPatchResponse",
    "TuneIdRetrieveResponse",
    "TuneListSortBy",
    "TuneParameters",
    "TuneResult",
    "TuneResultDatapointLoss",
    "TuneResultDatapoints",
    "TuneResultFiles",
    "TuneRetrieveResponse",
    "TuneStatus",
    "TunesResultDatapointLoss",
    "TuningTypeRetrieveResponse",
    "TuningTypeRetrieveResults",
    "UnauthorizedResponse",
    "UnavailableResponse",
    "UserApiKey",
    "UserCreateResponse",
    "UserCreateResult",
    "UserGenerationDefault",
    "UserPatchResponse",
    "UserResult",
    "UserRetrieveResponse",
]
